{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Objection Detection with RetinaNET.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxAJgA71-Dox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wgXTcyh-Rid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "082f24ba-c1f4-45ba-b6d3-946f281075ad"
      },
      "source": [
        "url = \"https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"data.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(\"data.zip\", \"r\") as z_fp:\n",
        "    z_fp.extractall(\"./\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/srihari-humbarwadi/datasets/releases/download/v0.1.0/data.zip\n",
            "560529408/560525318 [==============================] - 36s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB5CQ0kj-Tzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def swap_xy(boxes):\n",
        "    \"\"\"Swaps order the of x and y coordinates of the boxes.\n",
        "\n",
        "    Arguments:\n",
        "      boxes: A tensor with shape `(num_boxes, 4)` representing bounding boxes.\n",
        "\n",
        "    Returns:\n",
        "      swapped boxes with shape same as that of boxes.\n",
        "    \"\"\"\n",
        "    return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], axis = -1)\n",
        "\n",
        "\n",
        "def convert_to_xywh(boxes):\n",
        "    \"\"\"Changes the box format to center, width and height.\n",
        "\n",
        "    Arguments:\n",
        "      boxes: A tensor of rank 2 or higher with a shape of `(..., num_boxes, 4)`\n",
        "        representing bounding boxes where each box is of the format\n",
        "        `[xmin, ymin, xmax, ymax]`.\n",
        "\n",
        "    Returns:\n",
        "      converted boxes with shape same as that of boxes.\n",
        "    \"\"\"\n",
        "    return tf.concat(\n",
        "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
        "        axis = -1,\n",
        "    )\n",
        "\n",
        "\n",
        "def convert_to_corners(boxes):\n",
        "    \"\"\"Changes the box format to corner coordinates\n",
        "\n",
        "    Arguments:\n",
        "      boxes: A tensor of rank 2 or higher with a shape of `(..., num_boxes, 4)`\n",
        "        representing bounding boxes where each box is of the format\n",
        "        `[x, y, width, height]`.\n",
        "\n",
        "    Returns:\n",
        "      converted boxes with shape same as that of boxes.\n",
        "    \"\"\"\n",
        "    return tf.concat(\n",
        "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
        "        axis = -1,\n",
        "    )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Bd5qjs-4Rc",
        "colab_type": "text"
      },
      "source": [
        "### Computing pairwise Intersection Over Union (IOU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M-LcE_m-6yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_iou(boxes1, boxes2):\n",
        "    \"\"\"Computes pairwise IOU matrix for given two sets of boxes\n",
        "\n",
        "    Arguments:\n",
        "      boxes1: A tensor with shape `(N, 4)` representing bounding boxes\n",
        "        where each box is of the format `[x, y, width, height]`.\n",
        "        boxes2: A tensor with shape `(M, 4)` representing bounding boxes\n",
        "        where each box is of the format `[x, y, width, height]`.\n",
        "\n",
        "    Returns:\n",
        "      pairwise IOU matrix with shape `(N, M)`, where the value at ith row\n",
        "        jth column holds the IOU between ith box and jth box from\n",
        "        boxes1 and boxes2 respectively.\n",
        "    \"\"\"\n",
        "    boxes1_corners = convert_to_corners(boxes1)\n",
        "    boxes2_corners = convert_to_corners(boxes2)\n",
        "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
        "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
        "    intersection = tf.maximum(0.0, rd - lu)\n",
        "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "    boxes1_area = boxes1[:, 2] * boxes1[:, 3]\n",
        "    boxes2_area = boxes2[:, 2] * boxes2[:, 3]\n",
        "    union_area = tf.maximum(\n",
        "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
        "    )\n",
        "    return tf.clip_by_value(intersection_area / union_area, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def visualize_detections(\n",
        "    image, boxes, classes, scores, figsize = (7, 7), linewidth = 1, color = [0, 0, 1]\n",
        "):\n",
        "    \"\"\"Visualize Detections\"\"\"\n",
        "    image = np.array(image, dtype = np.uint8)\n",
        "    plt.figure(figsize = figsize)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(image)\n",
        "    ax = plt.gca()\n",
        "    for box, _cls, score in zip(boxes, classes, scores):\n",
        "        text = \"{}: {:.2f}\".format(_cls, score)\n",
        "        x1, y1, x2, y2 = box\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        patch = plt.Rectangle(\n",
        "            [x1, y1], w, h, fill = False, edgecolor = color, linewidth = linewidth\n",
        "        )\n",
        "        ax.add_patch(patch)\n",
        "        ax.text(\n",
        "            x1,\n",
        "            y1,\n",
        "            text,\n",
        "            bbox = {\"facecolor\": color, \"alpha\": 0.4},\n",
        "            clip_box = ax.clipbox,\n",
        "            clip_on = True,\n",
        "        )\n",
        "    plt.show()\n",
        "    return ax"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUF5aGlK_Upl",
        "colab_type": "text"
      },
      "source": [
        "### Implementing Anchor generator\n",
        "Anchor boxes are fixed sized boxes that the model uses to predict the bounding box for an object. It does this by regressing the offset between the location of the object's center and the center of an anchor box, and then uses the width and height of the anchor box to predict a relative scale of the object. In the case of RetinaNet, each location on a given feature map has nine anchor boxes (at three scales and three ratios)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2UoV1DX_WDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AnchorBox:\n",
        "    \"\"\"Generates anchor boxes.\n",
        "\n",
        "    This class has operations to generate anchor boxes for feature maps at\n",
        "    strides `[8, 16, 32, 64, 128]`. Where each anchor each box is of the\n",
        "    format `[x, y, width, height]`.\n",
        "\n",
        "    Attributes:\n",
        "      aspect_ratios: A list of float values representing the aspect ratios of\n",
        "        the anchor boxes at each location on the feature map\n",
        "      scales: A list of float values representing the scale of the anchor boxes\n",
        "        at each location on the feature map.\n",
        "      num_anchors: The number of anchor boxes at each location on feature map\n",
        "      areas: A list of float values representing the areas of the anchor\n",
        "        boxes for each feature map in the feature pyramid.\n",
        "      strides: A list of float value representing the strides for each feature\n",
        "        map in the feature pyramid.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
        "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
        "\n",
        "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
        "        self._strides = [2 ** i for i in range(3, 8)]\n",
        "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
        "        self._anchor_dims = self._compute_dims()\n",
        "\n",
        "    def _compute_dims(self):\n",
        "        \"\"\"Computes anchor box dimensions for all ratios and scales at all levels\n",
        "        of the feature pyramid.\n",
        "        \"\"\"\n",
        "        anchor_dims_all = []\n",
        "        for area in self._areas:\n",
        "            anchor_dims = []\n",
        "            for ratio in self.aspect_ratios:\n",
        "                anchor_height = tf.math.sqrt(area / ratio)\n",
        "                anchor_width = area / anchor_height\n",
        "                dims = tf.reshape(\n",
        "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
        "                )\n",
        "                for scale in self.scales:\n",
        "                    anchor_dims.append(scale * dims)\n",
        "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
        "        return anchor_dims_all\n",
        "\n",
        "    def _get_anchors(self, feature_height, feature_width, level):\n",
        "        \"\"\"Generates anchor boxes for a given feature map size and level\n",
        "\n",
        "        Arguments:\n",
        "          feature_height: An integer representing the height of the feature map.\n",
        "          feature_width: An integer representing the width of the feature map.\n",
        "          level: An integer representing the level of the feature map in the\n",
        "            feature pyramid.\n",
        "\n",
        "        Returns:\n",
        "          anchor boxes with the shape\n",
        "          `(feature_height * feature_width * num_anchors, 4)`\n",
        "        \"\"\"\n",
        "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
        "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
        "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 3]\n",
        "        centers = tf.expand_dims(centers, axis = -2)\n",
        "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
        "        dims = tf.tile(\n",
        "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
        "        )\n",
        "        anchors = tf.concat([centers, dims], axis = -1)\n",
        "        return tf.reshape(\n",
        "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
        "        )\n",
        "\n",
        "    def get_anchors(self, image_height, image_width):\n",
        "        \"\"\"Generates anchor boxes for all the feature maps of the feature pyramid.\n",
        "\n",
        "        Arguments:\n",
        "          image_height: Height of the input image.\n",
        "          image_width: Width of the input image.\n",
        "\n",
        "        Returns:\n",
        "          anchor boxes for all the feature maps, stacked as a single tensor\n",
        "            with shape `(total_anchors, 4)`\n",
        "        \"\"\"\n",
        "        anchors = [\n",
        "            self._get_anchors(\n",
        "                tf.math.ceil(image_height / 2 ** i),\n",
        "                tf.math.ceil(image_width / 2 ** i),\n",
        "                i,\n",
        "            )\n",
        "            for i in range(3, 8)\n",
        "        ]\n",
        "        return tf.concat(anchors, axis = 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQVqxMIbC4Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
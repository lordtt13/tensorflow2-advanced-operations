{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR model for reading Captchas.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ-0i9nol6pO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from tensorflow import keras\n",
        "from collections import Counter\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jx2usIEp0jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b8655e2-a479-48af-e4a8-d28959fdabf5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyWQL-BsoFQn",
        "colab_type": "text"
      },
      "source": [
        "### Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVqzV67MmMRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c0a5efb0-6bb6-4d16-cd42-506209be4506"
      },
      "source": [
        "!curl -LO https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip\n",
        "!unzip -qq captcha_images_v2.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   159  100   159    0     0   4416      0 --:--:-- --:--:-- --:--:--  4416\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 8863k  100 8863k    0     0  21.3M      0 --:--:-- --:--:-- --:--:-- 26.1M\n",
            "replace captcha_images_v2/ydd3g.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ4cCR6FmOta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cb8979d2-b62a-4bdf-90ad-131e7520947e"
      },
      "source": [
        "data_dir = Path(\"./captcha_images_v2/\")\n",
        "\n",
        "# Get list of all the images\n",
        "images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
        "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n",
        "characters = set(char for label in labels for char in label)\n",
        "\n",
        "print(\"Number of images found: \", len(images))\n",
        "print(\"Number of labels found: \", len(labels))\n",
        "print(\"Number of unique characters: \", len(characters))\n",
        "print(\"Characters present: \", characters)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "img_width = 200\n",
        "img_height = 50\n",
        "\n",
        "# Factor by which the image is going to be downsampled\n",
        "# by the convolutional blocks. We will be using two\n",
        "# convolution blocks and each block will have\n",
        "# a pooling layer which downsample the features by a factor of 2.\n",
        "# Hence total downsampling factor would be 4.\n",
        "downsample_factor = 4\n",
        "\n",
        "# Maximum length of any captcha in the dataset\n",
        "max_length = max([len(label) for label in labels])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images found:  1040\n",
            "Number of labels found:  1040\n",
            "Number of unique characters:  19\n",
            "Characters present:  {'y', '2', '7', '3', 'd', '5', 'n', 'c', 'm', '6', 'e', 'g', '4', 'x', '8', 'p', 'b', 'w', 'f'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZn0K-hPogbB",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3rC_RkjohtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping characters to integers\n",
        "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary = list(characters), num_oov_indices = 0, mask_token = None\n",
        ")\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary = char_to_num.get_vocabulary(), mask_token = None, invert = True\n",
        ")\n",
        "\n",
        "\n",
        "def split_data(images, labels, train_size = 0.9, shuffle = True):\n",
        "    size = len(images)\n",
        "    indices = np.arange(size)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    train_samples = int(size * train_size)\n",
        "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
        "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
        "    return x_train, x_valid, y_train, y_valid\n",
        "\n",
        "# Splitting data into training and validation sets\n",
        "x_train, x_valid, y_train, y_valid = split_data(np.array(images), np.array(labels))\n",
        "\n",
        "def encode_single_sample(img_path, label):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.io.decode_png(img, channels = 1)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, [img_height, img_width])\n",
        "    img = tf.transpose(img, perm = [1, 0, 2])\n",
        "    label = char_to_num(tf.strings.unicode_split(label, input_encoding = \"UTF-8\"))\n",
        "    return {\"image\": img, \"label\": label}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQy3fxuCo_fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalizations.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbtL1HzWocbG",
        "colab_type": "text"
      },
      "source": [
        "### Normalization Layers\n",
        "\n",
        "The basic idea behind these layers is to normalize the output of an activation layer to improve the convergence during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erib-mkDyTfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eae5add7-3040-4ef2-caee-1aad68c6403e"
      },
      "source": [
        "!pip install -q -U tensorflow-addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 28.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 399kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 430kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 440kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 460kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 471kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 491kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 501kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 522kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 532kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 542kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 563kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 573kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 593kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 604kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 614kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 624kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 634kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 645kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 665kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 675kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 686kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 696kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 706kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 716kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 727kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 737kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 747kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 768kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 778kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 788kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 798kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 808kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 819kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 829kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 839kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 849kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 860kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 870kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 880kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 890kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 901kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 911kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 921kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 942kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 952kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 962kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 972kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 983kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 993kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlgB5FciyUdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9b6_uMCyV-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2fcb4c9b-dc4d-4036-cd23-daa9819aa85c"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VzFCfAKyxoW",
        "colab_type": "text"
      },
      "source": [
        "### Group Normalization \n",
        "\n",
        "Group Normalization(GN) divides the channels of your inputs into smaller sub groups and normalizes these values based on their mean and variance. Since GN works on a single example this technique is batchsize independent.\n",
        "\n",
        "GN experimentally scored closed to batch normalization in image classification tasks. It can be beneficial to use GN instead of Batch Normalization in case your overall batch_size is low, which would lead to bad performance of batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3Ge76SDyz1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a71a5661-843a-4140-a2ba-792e41512167"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Reshape((28,28,1), input_shape = (28,28)),\n",
        "  tf.keras.layers.Conv2D(filters = 10, kernel_size = (3,3), data_format = \"channels_last\"),\n",
        "  # Groupnorm Layer\n",
        "  tfa.layers.GroupNormalization(groups = 5, axis = 3),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_test, y_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5022 - accuracy: 0.8508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4fd0433c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2IGNqP_zSqi",
        "colab_type": "text"
      },
      "source": [
        "### Instance Normalization \n",
        "\n",
        "Instance Normalization is special case of group normalization where the group size is the same size as the channel size (or the axis size).\n",
        "\n",
        "Experimental results show that instance normalization performs well on style transfer when replacing batch normalization. Recently, instance normalization has also been used as a replacement for batch normalization in GANs.\n",
        "\n",
        "Applying InstanceNormalization after a Conv2D Layer and using a uniformed initialized scale and offset factor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kk1jj6Yzafp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Reshape((28,28,1), input_shape = (28,28)),\n",
        "  tf.keras.layers.Conv2D(filters = 10, kernel_size = (3,3), data_format = \"channels_last\"),\n",
        "  # LayerNorm Layer\n",
        "  tfa.layers.InstanceNormalization(axis = 3, \n",
        "                                   center = True, \n",
        "                                   scale = True,\n",
        "                                   beta_initializer = \"random_uniform\",\n",
        "                                   gamma_initializer = \"random_uniform\"),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
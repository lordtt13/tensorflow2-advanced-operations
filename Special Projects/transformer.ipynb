{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea behind the Transformer model is self-attention—the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections Scaled dot product attention and Multi-head attention.\n",
    "\n",
    "A transformer model handles variable-sized input using stacks of self-attention layers instead of RNNs or CNNs. This general architecture has a number of advantages:\n",
    "\n",
    "- It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, StarCraft units).\n",
    "- Layer outputs can be calculated in parallel, instead of a series like an RNN.\n",
    "- Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see Scene Memory Transformer for example).\n",
    "- It can learn long-range dependencies. This is a challenge in many sequence tasks.\n",
    "\n",
    "The downsides of this architecture are:\n",
    "\n",
    "- For a time-series, the output for a time-step is calculated from the entire history instead of only the inputs and current hidden-state. This may be less efficient.\n",
    "- If the input does have a temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset ted_hrlr_translate/pt_to_en/1.0.0 (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to /home/tanmay/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f3e2e68dc74399884afff1009dbf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d683521eb94c424383bd1be8a9fa7974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab145edf4f74f0d9c0f11c0a80c6572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/tanmay/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteRMZ4SD/ted_hrlr_translate-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da28717d900c4f13ac731f19256e9210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=51785.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/tanmay/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteRMZ4SD/ted_hrlr_translate-validation.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66345892ed51445da932f255a1ed502e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1193.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/tanmay/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteRMZ4SD/ted_hrlr_translate-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aade50f76b4bbcb2e2e0276922fe32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1803.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset ted_hrlr_translate downloaded and prepared to /home/tanmay/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup Input Pipeline\n",
    "\n",
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info = True,\n",
    "                               as_supervised = True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom subwords tokenizer from the training dataset.\n",
    "\n",
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size = 2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size = 2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a start and end token to the input and target.\n",
    "\n",
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Dataset.map to apply this function to each element of the dataset\n",
    "\n",
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length = MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = (\n",
    "    train_examples\n",
    "    .map(tf_encode) \n",
    "    .filter(filter_max_length)\n",
    "    # cache the dataset to memory to get a speedup while reading from it.\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE))\n",
    "\n",
    "val_preprocessed = (\n",
    "    val_examples\n",
    "    .map(tf_encode)\n",
    "    .filter(filter_max_length))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (train_preprocessed\n",
    "                 .padded_batch(BATCH_SIZE, padded_shapes = ([None], [None]))\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "val_dataset = (val_preprocessed\n",
    "               .padded_batch(BATCH_SIZE,  padded_shapes = ([None], [None])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding\n",
    "\n",
    "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.\n",
    "\n",
    "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the similarity of their meaning and their position in the sentence, in the d-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap = 'RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dot product attention\n",
    "\n",
    "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value).\n",
    "\n",
    "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax.\n",
    "\n",
    "For example, consider that Q and K have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of dk. Hence, square root of dk is used for scaling (and not any other number) because the matmul of Q and K should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
    "\n",
    "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b = True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype = tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype = tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype = tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype = tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype = tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Pass all the queries together.\n",
    "\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype = tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention\n",
    "\n",
    "Multi-head attention consists of four parts:\n",
    "\n",
    "- Linear layers and split into heads.\n",
    "- Scaled dot-product attention.\n",
    "- Concatenation of heads.\n",
    "- Final linear layer.\n",
    "\n",
    "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.\n",
    "\n",
    "The scaled_dot_product_attention defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step. The attention output for each head is then concatenated (using tf.transpose, and tf.reshape) and put through a final Dense layer.\n",
    "\n",
    "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm = [0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm = [0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a MultiHeadAttention layer to try out. At each location in the sequence, y\n",
    "# The MultiHeadAttention runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location.\n",
    "\n",
    "temp_mha = MultiHeadAttention(d_model = 512, num_heads = 8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k = y, q = y, mask = None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point wise feed forward network\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation = 'relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and decoder\n",
    "\n",
    "The transformer model follows the same general pattern as a standard sequence to sequence with attention model.\n",
    "\n",
    "- The input sentence is passed through N encoder layers that generates an output for each word/token in the sequence.\n",
    "- The decoder attends on the encoder's output and its own input (self-attention) to predict the next word.\n",
    "\n",
    "## Encoder layer\n",
    "Each encoder layer consists of sublayers:\n",
    "\n",
    "- Multi-head attention (with padding mask)\n",
    "- Point wise feed forward networks.\n",
    "- Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
    "\n",
    "The output of each sublayer is LayerNorm(x + Sublayer(x)). The normalization is done on the d_model (last) axis. There are N encoder layers in the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training = training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training = training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder layer\n",
    "\n",
    "Each decoder layer consists of sublayers:\n",
    "\n",
    "- Masked multi-head attention (with look ahead mask and padding mask)\n",
    "- Multi-head attention (with padding mask). V (value) and K (key) receive the encoder output as inputs. Q (query) receives the output from the masked multi-head attention sublayer.\n",
    "- Point wise feed forward networks\n",
    "- Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is LayerNorm(x + Sublayer(x)). The normalization is done on the d_model (last) axis.\n",
    "\n",
    "There are N decoder layers in the transformer.\n",
    "\n",
    "As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate = 0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training = training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training = training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training = training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "The Encoder consists of:\n",
    "\n",
    "- Input Embedding\n",
    "- Positional Encoding\n",
    "- N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate = 0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training = training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers = 2, d_model = 512, num_heads = 8, \n",
    "                         dff = 2048, input_vocab_size = 8500,\n",
    "                         maximum_position_encoding = 10000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62), dtype = tf.int64, minval = 0, maxval = 200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training = False, mask = None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "The Decoder consists of:\n",
    "\n",
    "- Output Embedding\n",
    "- Positional Encoding\n",
    "- N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate = 0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training = training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers = 2, d_model = 512, num_heads = 8, \n",
    "                         dff = 2048, target_vocab_size = 8000,\n",
    "                         maximum_position_encoding = 5000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 26), dtype = tf.int64, minval = 0, maxval = 200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output = sample_encoder_output, \n",
    "                              training = False,\n",
    "                              look_ahead_mask = None, \n",
    "                              padding_mask = None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Transformer\n",
    "\n",
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate = 0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers = 2, d_model = 512, num_heads = 8, dff = 2048, \n",
    "    input_vocab_size = 8500, target_vocab_size = 8000, \n",
    "    pe_input = 10000, pe_target = 6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype = tf.int64, minval = 0, maxval = 200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype = tf.int64, minval = 0, maxval = 200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training = False, \n",
    "                               enc_padding_mask = None, \n",
    "                               look_ahead_mask = None,\n",
    "                               dec_padding_mask = None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values used in the base model of transformer were; num_layers=6, d_model = 512, dff = 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Adam optimizer with a custom learning rate scheduler according to the formula in the paper.\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps = 4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, \n",
    "                                     epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype = tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits = True, reduction = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype = loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name = 'train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Add\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input = input_vocab_size, \n",
    "                          pe_target = target_vocab_size,\n",
    "                          rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer = transformer,\n",
    "                           optimizer = optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep = 5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. tar_real is that same input shifted by 1: At each location in tar_input, tar_real contains the next token that should be predicted.\n",
    "\n",
    "For example, sentence = \"SOS A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "tar_inp = \"SOS A lion in the jungle is sleeping\"\n",
    "\n",
    "tar_real = \"A lion in the jungle is sleeping EOS\"\n",
    "\n",
    "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
    "\n",
    "During training this example uses teacher-forcing. Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
    "\n",
    "As the transformer predicts each word, self-attention allows it to look at the previous words in the input sequence to better predict the next word.\n",
    "\n",
    "To prevent the model from peaking at the expected output the model uses a look-ahead mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape = (None, None), dtype = tf.int64),\n",
    "    tf.TensorSpec(shape = (None, None), dtype = tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature = train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.0079 Accuracy 0.0008\n",
      "Epoch 1 Batch 50 Loss 8.9415 Accuracy 0.0046\n",
      "Epoch 1 Batch 100 Loss 8.8553 Accuracy 0.0149\n",
      "Epoch 1 Batch 150 Loss 8.7570 Accuracy 0.0187\n",
      "Epoch 1 Batch 200 Loss 8.6321 Accuracy 0.0209\n",
      "Epoch 1 Batch 250 Loss 8.4793 Accuracy 0.0238\n",
      "Epoch 1 Batch 300 Loss 8.3035 Accuracy 0.0275\n",
      "Epoch 1 Batch 350 Loss 8.1176 Accuracy 0.0309\n",
      "Epoch 1 Batch 400 Loss 7.9354 Accuracy 0.0337\n",
      "Epoch 1 Batch 450 Loss 7.7709 Accuracy 0.0367\n",
      "Epoch 1 Batch 500 Loss 7.6277 Accuracy 0.0395\n",
      "Epoch 1 Batch 550 Loss 7.4968 Accuracy 0.0424\n",
      "Epoch 1 Batch 600 Loss 7.3727 Accuracy 0.0459\n",
      "Epoch 1 Batch 650 Loss 7.2533 Accuracy 0.0493\n",
      "Epoch 1 Batch 700 Loss 7.1407 Accuracy 0.0527\n",
      "Epoch 1 Loss 7.1362 Accuracy 0.0528\n",
      "Time taken for 1 epoch: 85.24928212165833 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 5.6232 Accuracy 0.1098\n",
      "Epoch 2 Batch 50 Loss 5.5010 Accuracy 0.1043\n",
      "Epoch 2 Batch 100 Loss 5.4364 Accuracy 0.1063\n",
      "Epoch 2 Batch 150 Loss 5.3804 Accuracy 0.1083\n",
      "Epoch 2 Batch 200 Loss 5.3325 Accuracy 0.1101\n",
      "Epoch 2 Batch 250 Loss 5.2858 Accuracy 0.1121\n",
      "Epoch 2 Batch 300 Loss 5.2473 Accuracy 0.1139\n",
      "Epoch 2 Batch 350 Loss 5.2093 Accuracy 0.1155\n",
      "Epoch 2 Batch 400 Loss 5.1758 Accuracy 0.1172\n",
      "Epoch 2 Batch 450 Loss 5.1463 Accuracy 0.1185\n",
      "Epoch 2 Batch 500 Loss 5.1139 Accuracy 0.1200\n",
      "Epoch 2 Batch 550 Loss 5.0875 Accuracy 0.1213\n",
      "Epoch 2 Batch 600 Loss 5.0616 Accuracy 0.1228\n",
      "Epoch 2 Batch 650 Loss 5.0346 Accuracy 0.1242\n",
      "Epoch 2 Batch 700 Loss 5.0087 Accuracy 0.1254\n",
      "Epoch 2 Loss 5.0073 Accuracy 0.1254\n",
      "Time taken for 1 epoch: 49.72459578514099 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 4.6714 Accuracy 0.1461\n",
      "Epoch 3 Batch 50 Loss 4.5955 Accuracy 0.1429\n",
      "Epoch 3 Batch 100 Loss 4.6004 Accuracy 0.1445\n",
      "Epoch 3 Batch 150 Loss 4.5886 Accuracy 0.1452\n",
      "Epoch 3 Batch 200 Loss 4.5677 Accuracy 0.1458\n",
      "Epoch 3 Batch 250 Loss 4.5617 Accuracy 0.1462\n",
      "Epoch 3 Batch 300 Loss 4.5470 Accuracy 0.1467\n",
      "Epoch 3 Batch 350 Loss 4.5357 Accuracy 0.1471\n",
      "Epoch 3 Batch 400 Loss 4.5205 Accuracy 0.1482\n",
      "Epoch 3 Batch 450 Loss 4.5064 Accuracy 0.1490\n",
      "Epoch 3 Batch 500 Loss 4.4920 Accuracy 0.1500\n",
      "Epoch 3 Batch 550 Loss 4.4774 Accuracy 0.1506\n",
      "Epoch 3 Batch 600 Loss 4.4609 Accuracy 0.1515\n",
      "Epoch 3 Batch 650 Loss 4.4428 Accuracy 0.1522\n",
      "Epoch 3 Batch 700 Loss 4.4270 Accuracy 0.1531\n",
      "Epoch 3 Loss 4.4265 Accuracy 0.1532\n",
      "Time taken for 1 epoch: 51.27500367164612 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 4.0711 Accuracy 0.1727\n",
      "Epoch 4 Batch 50 Loss 4.1052 Accuracy 0.1700\n",
      "Epoch 4 Batch 100 Loss 4.0797 Accuracy 0.1704\n",
      "Epoch 4 Batch 150 Loss 4.0724 Accuracy 0.1712\n",
      "Epoch 4 Batch 200 Loss 4.0581 Accuracy 0.1723\n",
      "Epoch 4 Batch 250 Loss 4.0421 Accuracy 0.1741\n",
      "Epoch 4 Batch 300 Loss 4.0283 Accuracy 0.1751\n",
      "Epoch 4 Batch 350 Loss 4.0107 Accuracy 0.1761\n",
      "Epoch 4 Batch 400 Loss 3.9966 Accuracy 0.1766\n",
      "Epoch 4 Batch 450 Loss 3.9815 Accuracy 0.1780\n",
      "Epoch 4 Batch 500 Loss 3.9645 Accuracy 0.1791\n",
      "Epoch 4 Batch 550 Loss 3.9461 Accuracy 0.1802\n",
      "Epoch 4 Batch 600 Loss 3.9308 Accuracy 0.1814\n",
      "Epoch 4 Batch 650 Loss 3.9168 Accuracy 0.1825\n",
      "Epoch 4 Batch 700 Loss 3.9037 Accuracy 0.1831\n",
      "Epoch 4 Loss 3.9032 Accuracy 0.1831\n",
      "Time taken for 1 epoch: 52.83180570602417 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.4299 Accuracy 0.2211\n",
      "Epoch 5 Batch 50 Loss 3.5416 Accuracy 0.2036\n",
      "Epoch 5 Batch 100 Loss 3.5405 Accuracy 0.2013\n",
      "Epoch 5 Batch 150 Loss 3.5346 Accuracy 0.2020\n",
      "Epoch 5 Batch 200 Loss 3.5244 Accuracy 0.2023\n",
      "Epoch 5 Batch 250 Loss 3.5184 Accuracy 0.2026\n",
      "Epoch 5 Batch 300 Loss 3.5141 Accuracy 0.2033\n",
      "Epoch 5 Batch 350 Loss 3.5054 Accuracy 0.2042\n",
      "Epoch 5 Batch 400 Loss 3.5006 Accuracy 0.2045\n",
      "Epoch 5 Batch 450 Loss 3.4909 Accuracy 0.2050\n",
      "Epoch 5 Batch 500 Loss 3.4799 Accuracy 0.2060\n",
      "Epoch 5 Batch 550 Loss 3.4722 Accuracy 0.2066\n",
      "Epoch 5 Batch 600 Loss 3.4631 Accuracy 0.2075\n",
      "Epoch 5 Batch 650 Loss 3.4552 Accuracy 0.2079\n",
      "Epoch 5 Batch 700 Loss 3.4479 Accuracy 0.2082\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\n",
      "Epoch 5 Loss 3.4479 Accuracy 0.2082\n",
      "Time taken for 1 epoch: 52.74487328529358 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.2291 Accuracy 0.1955\n",
      "Epoch 6 Batch 50 Loss 3.1570 Accuracy 0.2194\n",
      "Epoch 6 Batch 100 Loss 3.1261 Accuracy 0.2213\n",
      "Epoch 6 Batch 150 Loss 3.1277 Accuracy 0.2223\n",
      "Epoch 6 Batch 200 Loss 3.1263 Accuracy 0.2231\n",
      "Epoch 6 Batch 250 Loss 3.1242 Accuracy 0.2237\n",
      "Epoch 6 Batch 300 Loss 3.1121 Accuracy 0.2241\n",
      "Epoch 6 Batch 350 Loss 3.1018 Accuracy 0.2250\n",
      "Epoch 6 Batch 400 Loss 3.0934 Accuracy 0.2257\n",
      "Epoch 6 Batch 450 Loss 3.0873 Accuracy 0.2265\n",
      "Epoch 6 Batch 500 Loss 3.0837 Accuracy 0.2270\n",
      "Epoch 6 Batch 550 Loss 3.0782 Accuracy 0.2274\n",
      "Epoch 6 Batch 600 Loss 3.0703 Accuracy 0.2277\n",
      "Epoch 6 Batch 650 Loss 3.0616 Accuracy 0.2285\n",
      "Epoch 6 Batch 700 Loss 3.0561 Accuracy 0.2289\n",
      "Epoch 6 Loss 3.0558 Accuracy 0.2289\n",
      "Time taken for 1 epoch: 51.90452790260315 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.8241 Accuracy 0.2437\n",
      "Epoch 7 Batch 50 Loss 2.7410 Accuracy 0.2460\n",
      "Epoch 7 Batch 100 Loss 2.7424 Accuracy 0.2446\n",
      "Epoch 7 Batch 150 Loss 2.7386 Accuracy 0.2465\n",
      "Epoch 7 Batch 200 Loss 2.7307 Accuracy 0.2465\n",
      "Epoch 7 Batch 250 Loss 2.7280 Accuracy 0.2458\n",
      "Epoch 7 Batch 300 Loss 2.7227 Accuracy 0.2459\n",
      "Epoch 7 Batch 350 Loss 2.7155 Accuracy 0.2463\n",
      "Epoch 7 Batch 400 Loss 2.7082 Accuracy 0.2469\n",
      "Epoch 7 Batch 450 Loss 2.7043 Accuracy 0.2474\n",
      "Epoch 7 Batch 500 Loss 2.6978 Accuracy 0.2480\n",
      "Epoch 7 Batch 550 Loss 2.6938 Accuracy 0.2478\n",
      "Epoch 7 Batch 600 Loss 2.6867 Accuracy 0.2484\n",
      "Epoch 7 Batch 650 Loss 2.6837 Accuracy 0.2486\n",
      "Epoch 7 Batch 700 Loss 2.6783 Accuracy 0.2489\n",
      "Epoch 7 Loss 2.6777 Accuracy 0.2489\n",
      "Time taken for 1 epoch: 52.36709809303284 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.2338 Accuracy 0.2640\n",
      "Epoch 8 Batch 50 Loss 2.3921 Accuracy 0.2617\n",
      "Epoch 8 Batch 100 Loss 2.3755 Accuracy 0.2652\n",
      "Epoch 8 Batch 150 Loss 2.3814 Accuracy 0.2642\n",
      "Epoch 8 Batch 200 Loss 2.3894 Accuracy 0.2639\n",
      "Epoch 8 Batch 250 Loss 2.3866 Accuracy 0.2645\n",
      "Epoch 8 Batch 300 Loss 2.3838 Accuracy 0.2647\n",
      "Epoch 8 Batch 350 Loss 2.3800 Accuracy 0.2652\n",
      "Epoch 8 Batch 400 Loss 2.3778 Accuracy 0.2655\n",
      "Epoch 8 Batch 450 Loss 2.3772 Accuracy 0.2656\n",
      "Epoch 8 Batch 500 Loss 2.3756 Accuracy 0.2661\n",
      "Epoch 8 Batch 550 Loss 2.3726 Accuracy 0.2666\n",
      "Epoch 8 Batch 600 Loss 2.3697 Accuracy 0.2668\n",
      "Epoch 8 Batch 650 Loss 2.3696 Accuracy 0.2670\n",
      "Epoch 8 Batch 700 Loss 2.3698 Accuracy 0.2671\n",
      "Epoch 8 Loss 2.3696 Accuracy 0.2671\n",
      "Time taken for 1 epoch: 54.169055223464966 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 2.0219 Accuracy 0.3014\n",
      "Epoch 9 Batch 50 Loss 2.1232 Accuracy 0.2751\n",
      "Epoch 9 Batch 100 Loss 2.1149 Accuracy 0.2774\n",
      "Epoch 9 Batch 150 Loss 2.1210 Accuracy 0.2788\n",
      "Epoch 9 Batch 200 Loss 2.1245 Accuracy 0.2794\n",
      "Epoch 9 Batch 250 Loss 2.1258 Accuracy 0.2803\n",
      "Epoch 9 Batch 300 Loss 2.1267 Accuracy 0.2809\n",
      "Epoch 9 Batch 350 Loss 2.1283 Accuracy 0.2813\n",
      "Epoch 9 Batch 400 Loss 2.1328 Accuracy 0.2809\n",
      "Epoch 9 Batch 450 Loss 2.1373 Accuracy 0.2811\n",
      "Epoch 9 Batch 500 Loss 2.1393 Accuracy 0.2808\n",
      "Epoch 9 Batch 550 Loss 2.1424 Accuracy 0.2809\n",
      "Epoch 9 Batch 600 Loss 2.1418 Accuracy 0.2810\n",
      "Epoch 9 Batch 650 Loss 2.1449 Accuracy 0.2806\n",
      "Epoch 9 Batch 700 Loss 2.1472 Accuracy 0.2805\n",
      "Epoch 9 Loss 2.1475 Accuracy 0.2805\n",
      "Time taken for 1 epoch: 59.13502478599548 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.8808 Accuracy 0.2800\n",
      "Epoch 10 Batch 50 Loss 1.9183 Accuracy 0.2901\n",
      "Epoch 10 Batch 100 Loss 1.9330 Accuracy 0.2905\n",
      "Epoch 10 Batch 150 Loss 1.9443 Accuracy 0.2919\n",
      "Epoch 10 Batch 200 Loss 1.9520 Accuracy 0.2911\n",
      "Epoch 10 Batch 250 Loss 1.9539 Accuracy 0.2912\n",
      "Epoch 10 Batch 300 Loss 1.9538 Accuracy 0.2911\n",
      "Epoch 10 Batch 350 Loss 1.9561 Accuracy 0.2907\n",
      "Epoch 10 Batch 400 Loss 1.9586 Accuracy 0.2906\n",
      "Epoch 10 Batch 450 Loss 1.9599 Accuracy 0.2912\n",
      "Epoch 10 Batch 500 Loss 1.9638 Accuracy 0.2911\n",
      "Epoch 10 Batch 550 Loss 1.9655 Accuracy 0.2911\n",
      "Epoch 10 Batch 600 Loss 1.9694 Accuracy 0.2908\n",
      "Epoch 10 Batch 650 Loss 1.9714 Accuracy 0.2906\n",
      "Epoch 10 Batch 700 Loss 1.9767 Accuracy 0.2901\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\n",
      "Epoch 10 Loss 1.9768 Accuracy 0.2901\n",
      "Time taken for 1 epoch: 52.83444428443909 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.8352 Accuracy 0.3057\n",
      "Epoch 11 Batch 50 Loss 1.7919 Accuracy 0.3002\n",
      "Epoch 11 Batch 100 Loss 1.7901 Accuracy 0.3013\n",
      "Epoch 11 Batch 150 Loss 1.8014 Accuracy 0.3014\n",
      "Epoch 11 Batch 200 Loss 1.7984 Accuracy 0.3008\n",
      "Epoch 11 Batch 250 Loss 1.8007 Accuracy 0.3007\n",
      "Epoch 11 Batch 300 Loss 1.8089 Accuracy 0.3007\n",
      "Epoch 11 Batch 350 Loss 1.8109 Accuracy 0.3007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 400 Loss 1.8149 Accuracy 0.2999\n",
      "Epoch 11 Batch 450 Loss 1.8183 Accuracy 0.3003\n",
      "Epoch 11 Batch 500 Loss 1.8214 Accuracy 0.3003\n",
      "Epoch 11 Batch 550 Loss 1.8256 Accuracy 0.2999\n",
      "Epoch 11 Batch 600 Loss 1.8273 Accuracy 0.3000\n",
      "Epoch 11 Batch 650 Loss 1.8320 Accuracy 0.2994\n",
      "Epoch 11 Batch 700 Loss 1.8367 Accuracy 0.2990\n",
      "Epoch 11 Loss 1.8364 Accuracy 0.2990\n",
      "Time taken for 1 epoch: 53.511075258255005 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.4985 Accuracy 0.2993\n",
      "Epoch 12 Batch 50 Loss 1.6545 Accuracy 0.3094\n",
      "Epoch 12 Batch 100 Loss 1.6613 Accuracy 0.3098\n",
      "Epoch 12 Batch 150 Loss 1.6629 Accuracy 0.3086\n",
      "Epoch 12 Batch 200 Loss 1.6773 Accuracy 0.3074\n",
      "Epoch 12 Batch 250 Loss 1.6873 Accuracy 0.3075\n",
      "Epoch 12 Batch 300 Loss 1.6914 Accuracy 0.3081\n",
      "Epoch 12 Batch 350 Loss 1.6956 Accuracy 0.3073\n",
      "Epoch 12 Batch 400 Loss 1.6954 Accuracy 0.3070\n",
      "Epoch 12 Batch 450 Loss 1.6990 Accuracy 0.3068\n",
      "Epoch 12 Batch 500 Loss 1.7035 Accuracy 0.3064\n",
      "Epoch 12 Batch 550 Loss 1.7101 Accuracy 0.3065\n",
      "Epoch 12 Batch 600 Loss 1.7138 Accuracy 0.3063\n",
      "Epoch 12 Batch 650 Loss 1.7184 Accuracy 0.3061\n",
      "Epoch 12 Batch 700 Loss 1.7230 Accuracy 0.3061\n",
      "Epoch 12 Loss 1.7237 Accuracy 0.3061\n",
      "Time taken for 1 epoch: 53.05849623680115 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.6014 Accuracy 0.3438\n",
      "Epoch 13 Batch 50 Loss 1.5636 Accuracy 0.3191\n",
      "Epoch 13 Batch 100 Loss 1.5732 Accuracy 0.3180\n",
      "Epoch 13 Batch 150 Loss 1.5784 Accuracy 0.3157\n",
      "Epoch 13 Batch 200 Loss 1.5844 Accuracy 0.3150\n",
      "Epoch 13 Batch 250 Loss 1.5854 Accuracy 0.3143\n",
      "Epoch 13 Batch 300 Loss 1.5863 Accuracy 0.3142\n",
      "Epoch 13 Batch 350 Loss 1.5906 Accuracy 0.3143\n",
      "Epoch 13 Batch 400 Loss 1.5953 Accuracy 0.3139\n",
      "Epoch 13 Batch 450 Loss 1.6001 Accuracy 0.3131\n",
      "Epoch 13 Batch 500 Loss 1.6058 Accuracy 0.3129\n",
      "Epoch 13 Batch 550 Loss 1.6118 Accuracy 0.3131\n",
      "Epoch 13 Batch 600 Loss 1.6168 Accuracy 0.3128\n",
      "Epoch 13 Batch 650 Loss 1.6212 Accuracy 0.3124\n",
      "Epoch 13 Batch 700 Loss 1.6259 Accuracy 0.3122\n",
      "Epoch 13 Loss 1.6259 Accuracy 0.3122\n",
      "Time taken for 1 epoch: 52.76702618598938 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.4624 Accuracy 0.3419\n",
      "Epoch 14 Batch 50 Loss 1.4597 Accuracy 0.3217\n",
      "Epoch 14 Batch 100 Loss 1.4697 Accuracy 0.3199\n",
      "Epoch 14 Batch 150 Loss 1.4790 Accuracy 0.3207\n",
      "Epoch 14 Batch 200 Loss 1.4863 Accuracy 0.3212\n",
      "Epoch 14 Batch 250 Loss 1.4935 Accuracy 0.3206\n",
      "Epoch 14 Batch 300 Loss 1.5034 Accuracy 0.3193\n",
      "Epoch 14 Batch 350 Loss 1.5074 Accuracy 0.3191\n",
      "Epoch 14 Batch 400 Loss 1.5126 Accuracy 0.3191\n",
      "Epoch 14 Batch 450 Loss 1.5159 Accuracy 0.3191\n",
      "Epoch 14 Batch 500 Loss 1.5202 Accuracy 0.3192\n",
      "Epoch 14 Batch 550 Loss 1.5251 Accuracy 0.3188\n",
      "Epoch 14 Batch 600 Loss 1.5331 Accuracy 0.3184\n",
      "Epoch 14 Batch 650 Loss 1.5360 Accuracy 0.3181\n",
      "Epoch 14 Batch 700 Loss 1.5405 Accuracy 0.3178\n",
      "Epoch 14 Loss 1.5406 Accuracy 0.3178\n",
      "Time taken for 1 epoch: 60.07309865951538 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.4959 Accuracy 0.3085\n",
      "Epoch 15 Batch 50 Loss 1.3923 Accuracy 0.3223\n",
      "Epoch 15 Batch 100 Loss 1.3979 Accuracy 0.3265\n",
      "Epoch 15 Batch 150 Loss 1.4023 Accuracy 0.3271\n",
      "Epoch 15 Batch 200 Loss 1.4099 Accuracy 0.3262\n",
      "Epoch 15 Batch 250 Loss 1.4173 Accuracy 0.3266\n",
      "Epoch 15 Batch 300 Loss 1.4236 Accuracy 0.3269\n",
      "Epoch 15 Batch 350 Loss 1.4276 Accuracy 0.3258\n",
      "Epoch 15 Batch 400 Loss 1.4312 Accuracy 0.3254\n",
      "Epoch 15 Batch 450 Loss 1.4409 Accuracy 0.3247\n",
      "Epoch 15 Batch 500 Loss 1.4453 Accuracy 0.3245\n",
      "Epoch 15 Batch 550 Loss 1.4489 Accuracy 0.3240\n",
      "Epoch 15 Batch 600 Loss 1.4536 Accuracy 0.3235\n",
      "Epoch 15 Batch 650 Loss 1.4599 Accuracy 0.3233\n",
      "Epoch 15 Batch 700 Loss 1.4657 Accuracy 0.3227\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3\n",
      "Epoch 15 Loss 1.4659 Accuracy 0.3227\n",
      "Time taken for 1 epoch: 53.74470782279968 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.3589 Accuracy 0.3725\n",
      "Epoch 16 Batch 50 Loss 1.3136 Accuracy 0.3316\n",
      "Epoch 16 Batch 100 Loss 1.3246 Accuracy 0.3335\n",
      "Epoch 16 Batch 150 Loss 1.3315 Accuracy 0.3318\n",
      "Epoch 16 Batch 200 Loss 1.3409 Accuracy 0.3310\n",
      "Epoch 16 Batch 250 Loss 1.3462 Accuracy 0.3307\n",
      "Epoch 16 Batch 300 Loss 1.3509 Accuracy 0.3310\n",
      "Epoch 16 Batch 350 Loss 1.3570 Accuracy 0.3304\n",
      "Epoch 16 Batch 400 Loss 1.3652 Accuracy 0.3300\n",
      "Epoch 16 Batch 450 Loss 1.3696 Accuracy 0.3299\n",
      "Epoch 16 Batch 500 Loss 1.3732 Accuracy 0.3293\n",
      "Epoch 16 Batch 550 Loss 1.3813 Accuracy 0.3287\n",
      "Epoch 16 Batch 600 Loss 1.3864 Accuracy 0.3282\n",
      "Epoch 16 Batch 650 Loss 1.3925 Accuracy 0.3281\n",
      "Epoch 16 Batch 700 Loss 1.4004 Accuracy 0.3277\n",
      "Epoch 16 Loss 1.4007 Accuracy 0.3278\n",
      "Time taken for 1 epoch: 53.72412467002869 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.2128 Accuracy 0.3137\n",
      "Epoch 17 Batch 50 Loss 1.2493 Accuracy 0.3337\n",
      "Epoch 17 Batch 100 Loss 1.2559 Accuracy 0.3380\n",
      "Epoch 17 Batch 150 Loss 1.2623 Accuracy 0.3373\n",
      "Epoch 17 Batch 200 Loss 1.2724 Accuracy 0.3364\n",
      "Epoch 17 Batch 250 Loss 1.2821 Accuracy 0.3359\n",
      "Epoch 17 Batch 300 Loss 1.2880 Accuracy 0.3349\n",
      "Epoch 17 Batch 350 Loss 1.2939 Accuracy 0.3348\n",
      "Epoch 17 Batch 400 Loss 1.3034 Accuracy 0.3342\n",
      "Epoch 17 Batch 450 Loss 1.3082 Accuracy 0.3343\n",
      "Epoch 17 Batch 500 Loss 1.3149 Accuracy 0.3343\n",
      "Epoch 17 Batch 550 Loss 1.3206 Accuracy 0.3340\n",
      "Epoch 17 Batch 600 Loss 1.3272 Accuracy 0.3334\n",
      "Epoch 17 Batch 650 Loss 1.3334 Accuracy 0.3330\n",
      "Epoch 17 Batch 700 Loss 1.3394 Accuracy 0.3324\n",
      "Epoch 17 Loss 1.3395 Accuracy 0.3324\n",
      "Time taken for 1 epoch: 52.67658233642578 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.1544 Accuracy 0.3177\n",
      "Epoch 18 Batch 50 Loss 1.2076 Accuracy 0.3434\n",
      "Epoch 18 Batch 100 Loss 1.2138 Accuracy 0.3394\n",
      "Epoch 18 Batch 150 Loss 1.2255 Accuracy 0.3397\n",
      "Epoch 18 Batch 200 Loss 1.2338 Accuracy 0.3383\n",
      "Epoch 18 Batch 250 Loss 1.2375 Accuracy 0.3372\n",
      "Epoch 18 Batch 300 Loss 1.2434 Accuracy 0.3367\n",
      "Epoch 18 Batch 350 Loss 1.2492 Accuracy 0.3372\n",
      "Epoch 18 Batch 400 Loss 1.2559 Accuracy 0.3368\n",
      "Epoch 18 Batch 450 Loss 1.2597 Accuracy 0.3366\n",
      "Epoch 18 Batch 500 Loss 1.2651 Accuracy 0.3366\n",
      "Epoch 18 Batch 550 Loss 1.2709 Accuracy 0.3369\n",
      "Epoch 18 Batch 600 Loss 1.2773 Accuracy 0.3364\n",
      "Epoch 18 Batch 650 Loss 1.2814 Accuracy 0.3357\n",
      "Epoch 18 Batch 700 Loss 1.2865 Accuracy 0.3358\n",
      "Epoch 18 Loss 1.2866 Accuracy 0.3358\n",
      "Time taken for 1 epoch: 52.16602349281311 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 1.1563 Accuracy 0.3811\n",
      "Epoch 19 Batch 50 Loss 1.1538 Accuracy 0.3418\n",
      "Epoch 19 Batch 100 Loss 1.1676 Accuracy 0.3411\n",
      "Epoch 19 Batch 150 Loss 1.1738 Accuracy 0.3409\n",
      "Epoch 19 Batch 200 Loss 1.1859 Accuracy 0.3405\n",
      "Epoch 19 Batch 250 Loss 1.1887 Accuracy 0.3419\n",
      "Epoch 19 Batch 300 Loss 1.1915 Accuracy 0.3418\n",
      "Epoch 19 Batch 350 Loss 1.1997 Accuracy 0.3419\n",
      "Epoch 19 Batch 400 Loss 1.2061 Accuracy 0.3414\n",
      "Epoch 19 Batch 450 Loss 1.2105 Accuracy 0.3411\n",
      "Epoch 19 Batch 500 Loss 1.2172 Accuracy 0.3406\n",
      "Epoch 19 Batch 550 Loss 1.2229 Accuracy 0.3399\n",
      "Epoch 19 Batch 600 Loss 1.2283 Accuracy 0.3395\n",
      "Epoch 19 Batch 650 Loss 1.2332 Accuracy 0.3393\n",
      "Epoch 19 Batch 700 Loss 1.2382 Accuracy 0.3388\n",
      "Epoch 19 Loss 1.2383 Accuracy 0.3389\n",
      "Time taken for 1 epoch: 52.29342603683472 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 1.0950 Accuracy 0.3455\n",
      "Epoch 20 Batch 50 Loss 1.0913 Accuracy 0.3460\n",
      "Epoch 20 Batch 100 Loss 1.1160 Accuracy 0.3446\n",
      "Epoch 20 Batch 150 Loss 1.1223 Accuracy 0.3449\n",
      "Epoch 20 Batch 200 Loss 1.1285 Accuracy 0.3456\n",
      "Epoch 20 Batch 250 Loss 1.1365 Accuracy 0.3454\n",
      "Epoch 20 Batch 300 Loss 1.1470 Accuracy 0.3447\n",
      "Epoch 20 Batch 350 Loss 1.1568 Accuracy 0.3445\n",
      "Epoch 20 Batch 400 Loss 1.1593 Accuracy 0.3442\n",
      "Epoch 20 Batch 450 Loss 1.1653 Accuracy 0.3443\n",
      "Epoch 20 Batch 500 Loss 1.1712 Accuracy 0.3439\n",
      "Epoch 20 Batch 550 Loss 1.1778 Accuracy 0.3433\n",
      "Epoch 20 Batch 600 Loss 1.1833 Accuracy 0.3429\n",
      "Epoch 20 Batch 650 Loss 1.1888 Accuracy 0.3427\n",
      "Epoch 20 Batch 700 Loss 1.1937 Accuracy 0.3425\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4\n",
      "Epoch 20 Loss 1.1942 Accuracy 0.3425\n",
      "Time taken for 1 epoch: 52.43977952003479 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "The following steps are used for evaluation:\n",
    "\n",
    "- Encode the input sentence using the Portuguese tokenizer (tokenizer_pt). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.\n",
    "- The decoder input is the start token == tokenizer_en.vocab_size.\n",
    "- Calculate the padding masks and the look ahead masks.\n",
    "- The decoder then outputs the predictions by looking at the encoder output and its own output (self-attention).\n",
    "- Select the last word and calculate the argmax of that.\n",
    "- Concatentate the predicted word to the decoder input as pass it to the decoder.\n",
    "- In this approach, the decoder predicts the next word based on the previous words it predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis = -1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis = 0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis = -1)\n",
    "\n",
    "  return tf.squeeze(output, axis = 0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize = (16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis = 0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap = 'viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict = fontdict, rotation = 90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict = fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot = ''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem that we have to solve the problem of there .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i 'm going to share very quickly share with you some bad stories that happened .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: this is the first book i did .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot = 'decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

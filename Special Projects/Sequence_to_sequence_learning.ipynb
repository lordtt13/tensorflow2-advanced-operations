{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to sequence learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P4Ouza3iApv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYyW6MkliIMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ju_ekL5ihML",
        "colab_type": "text"
      },
      "source": [
        "### Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBZ0DhZxiKkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4245bc7-c341-4558-aca7-88d1568f0ffa"
      },
      "source": [
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis = -1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "    \n",
        "print(\"Total questions:\", len(questions))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piWdAJ8xifjb",
        "colab_type": "text"
      },
      "source": [
        "### Vectorize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZoSSWEigSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7f9cc2d0-8470-4c3e-fd4e-dcb2b51f1502"
      },
      "source": [
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype = np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype = np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBDaEof4ir3b",
        "colab_type": "text"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHCDeYxVit2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "602ab41b-a0f3-4e5a-9816-f44aea62807c"
      },
      "source": [
        "num_layers = 1  \n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape = (None, num_feature).\n",
        "model.add(layers.LSTM(128, input_shape = (MAXLEN, len(chars))))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences = True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation = \"softmax\"))\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               72192     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4, 12)             1548      \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HATE5Bm5jG7q",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytljh38ijHu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0b4f7d9-2a81-4983-89b9-4b1ddc89b6a3"
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size = batch_size,\n",
        "        epochs = 1,\n",
        "        validation_data = (x_val, y_val),\n",
        "    )\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis = -1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax = False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end = \" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 1.7549 - accuracy: 0.3567 - val_loss: 1.5614 - val_accuracy: 0.4128\n",
            "Q 910+51  T 961  ☒ 906 \n",
            "Q 313+930 T 1243 ☒ 1336\n",
            "Q 90+240  T 330  ☒ 419 \n",
            "Q 520+39  T 559  ☒ 569 \n",
            "Q 382+488 T 870  ☒ 803 \n",
            "Q 5+221   T 226  ☑ 226 \n",
            "Q 18+710  T 728  ☒ 289 \n",
            "Q 777+625 T 1402 ☒ 1366\n",
            "Q 387+4   T 391  ☒ 486 \n",
            "Q 358+3   T 361  ☒ 556 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.3421 - accuracy: 0.4979 - val_loss: 1.1491 - val_accuracy: 0.5707\n",
            "Q 36+754  T 790  ☒ 766 \n",
            "Q 315+70  T 385  ☒ 378 \n",
            "Q 628+3   T 631  ☒ 628 \n",
            "Q 401+631 T 1032 ☒ 102 \n",
            "Q 97+660  T 757  ☒ 736 \n",
            "Q 295+695 T 990  ☒ 102 \n",
            "Q 60+404  T 464  ☒ 428 \n",
            "Q 195+759 T 954  ☒ 102 \n",
            "Q 96+140  T 236  ☒ 208 \n",
            "Q 331+96  T 427  ☒ 418 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 1.0263 - accuracy: 0.6191 - val_loss: 0.9209 - val_accuracy: 0.6628\n",
            "Q 325+31  T 356  ☒ 354 \n",
            "Q 520+5   T 525  ☑ 525 \n",
            "Q 900+991 T 1891 ☒ 1801\n",
            "Q 29+274  T 303  ☒ 307 \n",
            "Q 12+31   T 43   ☒ 45  \n",
            "Q 35+860  T 895  ☒ 885 \n",
            "Q 827+702 T 1529 ☒ 1444\n",
            "Q 55+881  T 936  ☒ 935 \n",
            "Q 905+265 T 1170 ☒ 1117\n",
            "Q 2+158   T 160  ☒ 167 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.8561 - accuracy: 0.6859 - val_loss: 0.8075 - val_accuracy: 0.7072\n",
            "Q 33+279  T 312  ☑ 312 \n",
            "Q 5+981   T 986  ☒ 994 \n",
            "Q 564+68  T 632  ☑ 632 \n",
            "Q 19+79   T 98   ☒ 90  \n",
            "Q 577+358 T 935  ☒ 942 \n",
            "Q 103+76  T 179  ☒ 182 \n",
            "Q 6+347   T 353  ☒ 352 \n",
            "Q 762+468 T 1230 ☒ 1222\n",
            "Q 969+73  T 1042 ☑ 1042\n",
            "Q 327+4   T 331  ☒ 332 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.7622 - accuracy: 0.7224 - val_loss: 0.7257 - val_accuracy: 0.7390\n",
            "Q 5+34    T 39   ☒ 40  \n",
            "Q 873+172 T 1045 ☒ 1041\n",
            "Q 87+621  T 708  ☒ 702 \n",
            "Q 98+254  T 352  ☑ 352 \n",
            "Q 95+178  T 273  ☒ 272 \n",
            "Q 568+93  T 661  ☒ 662 \n",
            "Q 81+313  T 394  ☒ 392 \n",
            "Q 30+39   T 69   ☒ 64  \n",
            "Q 92+899  T 991  ☒ 982 \n",
            "Q 349+107 T 456  ☒ 462 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.6439 - accuracy: 0.7654 - val_loss: 0.5358 - val_accuracy: 0.7987\n",
            "Q 508+192 T 700  ☒ 698 \n",
            "Q 4+24    T 28   ☒ 38  \n",
            "Q 66+886  T 952  ☑ 952 \n",
            "Q 9+414   T 423  ☑ 423 \n",
            "Q 572+573 T 1145 ☒ 1156\n",
            "Q 51+27   T 78   ☑ 78  \n",
            "Q 2+512   T 514  ☑ 514 \n",
            "Q 29+43   T 72   ☒ 70  \n",
            "Q 65+44   T 109  ☒ 108 \n",
            "Q 7+676   T 683  ☑ 683 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.3428 - accuracy: 0.8896 - val_loss: 0.2197 - val_accuracy: 0.9459\n",
            "Q 75+191  T 266  ☑ 266 \n",
            "Q 77+350  T 427  ☑ 427 \n",
            "Q 84+22   T 106  ☑ 106 \n",
            "Q 865+37  T 902  ☑ 902 \n",
            "Q 634+355 T 989  ☒ 999 \n",
            "Q 124+810 T 934  ☒ 924 \n",
            "Q 662+509 T 1171 ☒ 1161\n",
            "Q 137+349 T 486  ☑ 486 \n",
            "Q 239+758 T 997  ☒ 998 \n",
            "Q 762+468 T 1230 ☑ 1230\n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1734 - accuracy: 0.9576 - val_loss: 0.1296 - val_accuracy: 0.9697\n",
            "Q 777+625 T 1402 ☒ 1401\n",
            "Q 149+500 T 649  ☑ 649 \n",
            "Q 5+25    T 30   ☒ 20  \n",
            "Q 768+20  T 788  ☑ 788 \n",
            "Q 592+604 T 1196 ☑ 1196\n",
            "Q 58+901  T 959  ☑ 959 \n",
            "Q 852+7   T 859  ☑ 859 \n",
            "Q 250+49  T 299  ☑ 299 \n",
            "Q 47+503  T 550  ☑ 550 \n",
            "Q 685+98  T 783  ☑ 783 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.1055 - accuracy: 0.9755 - val_loss: 0.0769 - val_accuracy: 0.9837\n",
            "Q 908+759 T 1667 ☒ 1767\n",
            "Q 326+16  T 342  ☑ 342 \n",
            "Q 96+604  T 700  ☑ 700 \n",
            "Q 60+552  T 612  ☑ 612 \n",
            "Q 667+12  T 679  ☑ 679 \n",
            "Q 23+28   T 51   ☑ 51  \n",
            "Q 896+977 T 1873 ☒ 1973\n",
            "Q 73+28   T 101  ☑ 101 \n",
            "Q 56+809  T 865  ☑ 865 \n",
            "Q 94+45   T 139  ☑ 139 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0785 - accuracy: 0.9806 - val_loss: 0.0638 - val_accuracy: 0.9851\n",
            "Q 13+52   T 65   ☑ 65  \n",
            "Q 30+593  T 623  ☑ 623 \n",
            "Q 409+195 T 604  ☑ 604 \n",
            "Q 89+858  T 947  ☑ 947 \n",
            "Q 38+899  T 937  ☑ 937 \n",
            "Q 894+97  T 991  ☒ 981 \n",
            "Q 491+12  T 503  ☑ 503 \n",
            "Q 368+464 T 832  ☑ 832 \n",
            "Q 903+308 T 1211 ☑ 1211\n",
            "Q 239+616 T 855  ☑ 855 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0432 - accuracy: 0.9912 - val_loss: 0.0445 - val_accuracy: 0.9889\n",
            "Q 43+325  T 368  ☑ 368 \n",
            "Q 93+59   T 152  ☑ 152 \n",
            "Q 10+226  T 236  ☑ 236 \n",
            "Q 231+380 T 611  ☑ 611 \n",
            "Q 637+465 T 1102 ☑ 1102\n",
            "Q 310+57  T 367  ☑ 367 \n",
            "Q 2+488   T 490  ☑ 490 \n",
            "Q 456+73  T 529  ☑ 529 \n",
            "Q 219+230 T 449  ☑ 449 \n",
            "Q 853+698 T 1551 ☑ 1551\n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0509 - accuracy: 0.9865 - val_loss: 0.0283 - val_accuracy: 0.9941\n",
            "Q 77+695  T 772  ☑ 772 \n",
            "Q 38+693  T 731  ☑ 731 \n",
            "Q 9+379   T 388  ☑ 388 \n",
            "Q 841+48  T 889  ☑ 889 \n",
            "Q 75+957  T 1032 ☑ 1032\n",
            "Q 5+769   T 774  ☑ 774 \n",
            "Q 384+128 T 512  ☑ 512 \n",
            "Q 233+21  T 254  ☑ 254 \n",
            "Q 55+527  T 582  ☑ 582 \n",
            "Q 515+52  T 567  ☑ 567 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 0.0186 - val_accuracy: 0.9968\n",
            "Q 11+854  T 865  ☑ 865 \n",
            "Q 325+46  T 371  ☑ 371 \n",
            "Q 611+770 T 1381 ☑ 1381\n",
            "Q 864+31  T 895  ☑ 895 \n",
            "Q 425+38  T 463  ☑ 463 \n",
            "Q 29+79   T 108  ☑ 108 \n",
            "Q 638+94  T 732  ☑ 732 \n",
            "Q 0+169   T 169  ☑ 169 \n",
            "Q 73+863  T 936  ☑ 936 \n",
            "Q 43+893  T 936  ☑ 936 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0345 - accuracy: 0.9919 - val_loss: 0.0187 - val_accuracy: 0.9962\n",
            "Q 608+78  T 686  ☑ 686 \n",
            "Q 7+694   T 701  ☑ 701 \n",
            "Q 478+465 T 943  ☑ 943 \n",
            "Q 739+44  T 783  ☑ 783 \n",
            "Q 88+575  T 663  ☑ 663 \n",
            "Q 278+454 T 732  ☑ 732 \n",
            "Q 22+193  T 215  ☑ 215 \n",
            "Q 188+93  T 281  ☑ 281 \n",
            "Q 584+497 T 1081 ☑ 1081\n",
            "Q 263+174 T 437  ☑ 437 \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0365 - accuracy: 0.9898 - val_loss: 0.0302 - val_accuracy: 0.9923\n",
            "Q 641+1   T 642  ☑ 642 \n",
            "Q 101+22  T 123  ☑ 123 \n",
            "Q 274+387 T 661  ☑ 661 \n",
            "Q 651+72  T 723  ☑ 723 \n",
            "Q 883+541 T 1424 ☑ 1424\n",
            "Q 886+225 T 1111 ☑ 1111\n",
            "Q 14+229  T 243  ☑ 243 \n",
            "Q 831+53  T 884  ☑ 884 \n",
            "Q 69+753  T 822  ☑ 822 \n",
            "Q 680+262 T 942  ☑ 942 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0323 - accuracy: 0.9920 - val_loss: 0.1052 - val_accuracy: 0.9628\n",
            "Q 907+79  T 986  ☑ 986 \n",
            "Q 87+602  T 689  ☑ 689 \n",
            "Q 6+327   T 333  ☒ 334 \n",
            "Q 712+54  T 766  ☑ 766 \n",
            "Q 22+593  T 615  ☑ 615 \n",
            "Q 57+371  T 428  ☑ 428 \n",
            "Q 186+977 T 1163 ☒ 1263\n",
            "Q 825+359 T 1184 ☑ 1184\n",
            "Q 436+70  T 506  ☑ 506 \n",
            "Q 30+228  T 258  ☑ 258 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 0.0628 - val_accuracy: 0.9794\n",
            "Q 320+48  T 368  ☑ 368 \n",
            "Q 318+47  T 365  ☑ 365 \n",
            "Q 857+538 T 1395 ☑ 1395\n",
            "Q 120+47  T 167  ☑ 167 \n",
            "Q 51+226  T 277  ☑ 277 \n",
            "Q 2+509   T 511  ☑ 511 \n",
            "Q 14+14   T 28   ☑ 28  \n",
            "Q 85+886  T 971  ☑ 971 \n",
            "Q 21+39   T 60   ☑ 60  \n",
            "Q 511+1   T 512  ☑ 512 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0263 - accuracy: 0.9929 - val_loss: 0.0078 - val_accuracy: 0.9990\n",
            "Q 734+32  T 766  ☑ 766 \n",
            "Q 96+633  T 729  ☑ 729 \n",
            "Q 548+70  T 618  ☑ 618 \n",
            "Q 636+85  T 721  ☑ 721 \n",
            "Q 88+91   T 179  ☑ 179 \n",
            "Q 76+944  T 1020 ☑ 1020\n",
            "Q 170+2   T 172  ☑ 172 \n",
            "Q 515+64  T 579  ☑ 579 \n",
            "Q 504+901 T 1405 ☑ 1405\n",
            "Q 9+123   T 132  ☑ 132 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.0420 - val_accuracy: 0.9865\n",
            "Q 303+35  T 338  ☑ 338 \n",
            "Q 726+98  T 824  ☑ 824 \n",
            "Q 562+810 T 1372 ☑ 1372\n",
            "Q 615+42  T 657  ☑ 657 \n",
            "Q 9+379   T 388  ☑ 388 \n",
            "Q 67+446  T 513  ☑ 513 \n",
            "Q 559+3   T 562  ☑ 562 \n",
            "Q 45+127  T 172  ☑ 172 \n",
            "Q 772+376 T 1148 ☑ 1148\n",
            "Q 733+850 T 1583 ☑ 1583\n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 8s 5ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0064 - val_accuracy: 0.9990\n",
            "Q 827+702 T 1529 ☑ 1529\n",
            "Q 68+690  T 758  ☑ 758 \n",
            "Q 43+939  T 982  ☑ 982 \n",
            "Q 258+8   T 266  ☑ 266 \n",
            "Q 23+50   T 73   ☑ 73  \n",
            "Q 166+63  T 229  ☑ 229 \n",
            "Q 96+134  T 230  ☑ 230 \n",
            "Q 17+286  T 303  ☑ 303 \n",
            "Q 973+92  T 1065 ☑ 1065\n",
            "Q 79+496  T 575  ☑ 575 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0255 - accuracy: 0.9928 - val_loss: 0.0089 - val_accuracy: 0.9979\n",
            "Q 90+575  T 665  ☑ 665 \n",
            "Q 581+964 T 1545 ☑ 1545\n",
            "Q 266+755 T 1021 ☑ 1021\n",
            "Q 171+481 T 652  ☑ 652 \n",
            "Q 25+62   T 87   ☑ 87  \n",
            "Q 307+465 T 772  ☑ 772 \n",
            "Q 15+409  T 424  ☑ 424 \n",
            "Q 239+758 T 997  ☒ 998 \n",
            "Q 89+99   T 188  ☑ 188 \n",
            "Q 17+571  T 588  ☑ 588 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.0067 - val_accuracy: 0.9988\n",
            "Q 82+965  T 1047 ☑ 1047\n",
            "Q 48+81   T 129  ☑ 129 \n",
            "Q 548+70  T 618  ☑ 618 \n",
            "Q 809+663 T 1472 ☑ 1472\n",
            "Q 492+87  T 579  ☑ 579 \n",
            "Q 55+860  T 915  ☑ 915 \n",
            "Q 1+181   T 182  ☑ 182 \n",
            "Q 6+134   T 140  ☑ 140 \n",
            "Q 426+91  T 517  ☑ 517 \n",
            "Q 3+161   T 164  ☑ 164 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
            "Q 637+48  T 685  ☑ 685 \n",
            "Q 28+60   T 88   ☑ 88  \n",
            "Q 301+99  T 400  ☑ 400 \n",
            "Q 53+341  T 394  ☑ 394 \n",
            "Q 514+25  T 539  ☑ 539 \n",
            "Q 195+92  T 287  ☑ 287 \n",
            "Q 70+468  T 538  ☑ 538 \n",
            "Q 509+306 T 815  ☑ 815 \n",
            "Q 56+662  T 718  ☑ 718 \n",
            "Q 133+226 T 359  ☑ 359 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0057 - val_accuracy: 0.9991\n",
            "Q 5+500   T 505  ☑ 505 \n",
            "Q 54+80   T 134  ☑ 134 \n",
            "Q 219+44  T 263  ☑ 263 \n",
            "Q 60+509  T 569  ☑ 569 \n",
            "Q 588+280 T 868  ☑ 868 \n",
            "Q 60+770  T 830  ☑ 830 \n",
            "Q 536+420 T 956  ☑ 956 \n",
            "Q 747+0   T 747  ☑ 747 \n",
            "Q 27+4    T 31   ☑ 31  \n",
            "Q 9+459   T 468  ☑ 468 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0049 - val_accuracy: 0.9993\n",
            "Q 104+836 T 940  ☑ 940 \n",
            "Q 503+761 T 1264 ☑ 1264\n",
            "Q 638+94  T 732  ☑ 732 \n",
            "Q 676+93  T 769  ☑ 769 \n",
            "Q 527+2   T 529  ☑ 529 \n",
            "Q 80+64   T 144  ☑ 144 \n",
            "Q 104+49  T 153  ☑ 153 \n",
            "Q 55+354  T 409  ☑ 409 \n",
            "Q 49+963  T 1012 ☑ 1012\n",
            "Q 253+371 T 624  ☑ 624 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0046 - val_accuracy: 0.9996\n",
            "Q 1+948   T 949  ☑ 949 \n",
            "Q 815+1   T 816  ☑ 816 \n",
            "Q 254+872 T 1126 ☑ 1126\n",
            "Q 444+0   T 444  ☑ 444 \n",
            "Q 835+74  T 909  ☑ 909 \n",
            "Q 5+787   T 792  ☑ 792 \n",
            "Q 122+720 T 842  ☑ 842 \n",
            "Q 603+539 T 1142 ☑ 1142\n",
            "Q 13+421  T 434  ☑ 434 \n",
            "Q 23+8    T 31   ☑ 31  \n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0034 - val_accuracy: 0.9996\n",
            "Q 559+857 T 1416 ☑ 1416\n",
            "Q 18+644  T 662  ☑ 662 \n",
            "Q 925+6   T 931  ☑ 931 \n",
            "Q 33+957  T 990  ☑ 990 \n",
            "Q 497+60  T 557  ☑ 557 \n",
            "Q 431+47  T 478  ☑ 478 \n",
            "Q 749+36  T 785  ☑ 785 \n",
            "Q 68+272  T 340  ☑ 340 \n",
            "Q 501+454 T 955  ☑ 955 \n",
            "Q 90+758  T 848  ☑ 848 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
            "Q 22+4    T 26   ☑ 26  \n",
            "Q 346+653 T 999  ☑ 999 \n",
            "Q 60+733  T 793  ☑ 793 \n",
            "Q 150+126 T 276  ☑ 276 \n",
            "Q 74+965  T 1039 ☑ 1039\n",
            "Q 2+404   T 406  ☑ 406 \n",
            "Q 7+929   T 936  ☑ 936 \n",
            "Q 876+89  T 965  ☑ 965 \n",
            "Q 191+612 T 803  ☑ 803 \n",
            "Q 1+332   T 333  ☑ 333 \n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 7s 5ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
            "Q 169+820 T 989  ☑ 989 \n",
            "Q 478+465 T 943  ☑ 943 \n",
            "Q 571+214 T 785  ☑ 785 \n",
            "Q 32+994  T 1026 ☑ 1026\n",
            "Q 768+53  T 821  ☑ 821 \n",
            "Q 821+273 T 1094 ☑ 1094\n",
            "Q 7+553   T 560  ☑ 560 \n",
            "Q 276+43  T 319  ☑ 319 \n",
            "Q 274+48  T 322  ☑ 322 \n",
            "Q 39+262  T 301  ☑ 301 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
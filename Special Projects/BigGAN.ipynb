{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsbUfcy43-Xq",
        "colab_type": "text"
      },
      "source": [
        "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmYkmOd_4RpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from scipy.stats import truncnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mCbVN1H4YAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7dee3734-f291-46f1-e06e-9108d041221f"
      },
      "source": [
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eScvIjEl4Bqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select from anyone of these, according to your choice\n",
        "\n",
        "# BigGAN-deep models\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-deep-128/1'  # 128x128 BigGAN-deep\n",
        "module_path = 'https://tfhub.dev/deepmind/biggan-deep-256/1'  # 256x256 BigGAN-deep\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-deep-512/1'  # 512x512 BigGAN-deep\n",
        "\n",
        "# BigGAN (original) models\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-128/2'  # 128x128 BigGAN\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-256/2'  # 256x256 BigGAN\n",
        "# module_path = 'https://tfhub.dev/deepmind/biggan-512/2'  # 512x512 BigGAN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF9ei-vZ4O7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "cfe11466-fe93-4f01-897e-e90cf1940a16"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "print('Loading BigGAN module from:', module_path)\n",
        "module = hub.Module(module_path)\n",
        "inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)\n",
        "          for k, v in module.get_input_info_dict().items()}\n",
        "output = module(inputs)\n",
        "\n",
        "print()\n",
        "print('Inputs:\\n', '\\n'.join(\n",
        "    '  {}: {}'.format(*kv) for kv in inputs.items()))\n",
        "print()\n",
        "print('Output:', output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BigGAN module from: https://tfhub.dev/deepmind/biggan-deep-256/1\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Inputs:\n",
            "   y: Tensor(\"y:0\", shape=(?, 1000), dtype=float32)\n",
            "  z: Tensor(\"z:0\", shape=(?, 128), dtype=float32)\n",
            "  truncation: Tensor(\"truncation:0\", shape=(), dtype=float32)\n",
            "\n",
            "Output: Tensor(\"module_apply_default/G_trunc_output:0\", shape=(?, 256, 256, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfeOZecq4l7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_z = inputs['z']\n",
        "input_y = inputs['y']\n",
        "input_trunc = inputs['truncation']\n",
        "\n",
        "dim_z = input_z.shape.as_list()[1]\n",
        "vocab_size = input_y.shape.as_list()[1]\n",
        "\n",
        "def truncated_z_sample(batch_size, truncation = 1., seed = None):\n",
        "  state = None if seed is None else np.random.RandomState(seed)\n",
        "  values = truncnorm.rvs(-2, 2, size = (batch_size, dim_z), random_state = state)\n",
        "  return truncation * values\n",
        "\n",
        "def one_hot(index, vocab_size = vocab_size):\n",
        "  index = np.asarray(index)\n",
        "  if len(index.shape) == 0:\n",
        "    index = np.asarray([index])\n",
        "  assert len(index.shape) == 1\n",
        "  num = index.shape[0]\n",
        "  output = np.zeros((num, vocab_size), dtype = np.float32)\n",
        "  output[np.arange(num), index] = 1\n",
        "  return output\n",
        "\n",
        "def one_hot_if_needed(label, vocab_size = vocab_size):\n",
        "  label = np.asarray(label)\n",
        "  if len(label.shape) <= 1:\n",
        "    label = one_hot(label, vocab_size)\n",
        "  assert len(label.shape) == 2\n",
        "  return label\n",
        "\n",
        "def sample(sess, noise, label, truncation = 1., batch_size = 8,\n",
        "           vocab_size = vocab_size):\n",
        "  noise = np.asarray(noise)\n",
        "  label = np.asarray(label)\n",
        "  num = noise.shape[0]\n",
        "  if len(label.shape) == 0:\n",
        "    label = np.asarray([label] * num)\n",
        "  if label.shape[0] != num:\n",
        "    raise ValueError('Got # noise samples ({}) != # label samples ({})'\n",
        "                     .format(noise.shape[0], label.shape[0]))\n",
        "  label = one_hot_if_needed(label, vocab_size)\n",
        "  ims = []\n",
        "  for batch_start in range(0, num, batch_size):\n",
        "    s = slice(batch_start, min(num, batch_start + batch_size))\n",
        "    feed_dict = {input_z: noise[s], input_y: label[s], input_trunc: truncation}\n",
        "    ims.append(sess.run(output, feed_dict=feed_dict))\n",
        "  ims = np.concatenate(ims, axis = 0)\n",
        "  assert ims.shape[0] == num\n",
        "  ims = np.clip(((ims + 1) / 2.0) * 256, 0, 255)\n",
        "  ims = np.uint8(ims)\n",
        "  return ims\n",
        "\n",
        "def interpolate(A, B, num_interps):\n",
        "  if A.shape != B.shape:\n",
        "    raise ValueError('A and B must have the same shape to interpolate.')\n",
        "  alphas = np.linspace(0, 1, num_interps)\n",
        "  return np.array([(1-a)*A + a*B for a in alphas])\n",
        "\n",
        "def imgrid(imarray, cols=5, pad=1):\n",
        "  if imarray.dtype != np.uint8:\n",
        "    raise ValueError('imgrid input imarray must be uint8')\n",
        "  pad = int(pad)\n",
        "  assert pad >= 0\n",
        "  cols = int(cols)\n",
        "  assert cols >= 1\n",
        "  N, H, W, C = imarray.shape\n",
        "  rows = N // cols + int(N % cols != 0)\n",
        "  batch_pad = rows * cols - N\n",
        "  assert batch_pad >= 0\n",
        "  post_pad = [batch_pad, pad, pad, 0]\n",
        "  pad_arg = [[0, p] for p in post_pad]\n",
        "  imarray = np.pad(imarray, pad_arg, 'constant', constant_values = 255)\n",
        "  H += pad\n",
        "  W += pad\n",
        "  grid = (imarray\n",
        "          .reshape(rows, cols, H, W, C)\n",
        "          .transpose(0, 2, 1, 3, 4)\n",
        "          .reshape(rows*H, cols*W, C))\n",
        "  if pad:\n",
        "    grid = grid[:-pad, :-pad]\n",
        "  return grid\n",
        "\n",
        "def imshow(a, format = 'png', jpeg_fallback = True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  data = io.BytesIO()\n",
        "  PIL.Image.fromarray(a).save(data, format)\n",
        "  im_data = data.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print(('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format))\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_vERaaz55bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2vtM6VOA2myH"
   },
   "outputs": [],
   "source": [
    "# import the libraries as shown below\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, GlobalMaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E9LVvrX52myH"
   },
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'COVID-19_Radiography_Dataset'\n",
    "#valid_path = 'Datasets/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KC7xvbxd2myI",
    "outputId": "01e900c7-9f05-41a5-c821-3d8daf4095dd"
   },
   "outputs": [],
   "source": [
    "# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n",
    "# Here we will be using imagenet weights\n",
    " \n",
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WOfDBv_r2myI"
   },
   "outputs": [],
   "source": [
    "# don't train existing weights\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L1aH4N0L2myJ"
   },
   "outputs": [],
   "source": [
    "# useful for getting number of output classes\n",
    "folders = glob('COVID-19_Radiography_Dataset/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWNK4Usd2myJ",
    "outputId": "10d4731e-df38-4a67-e2b3-0acaed446ddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COVID-19_Radiography_Dataset/COVID',\n",
       " 'COVID-19_Radiography_Dataset/Normal',\n",
       " 'COVID-19_Radiography_Dataset/Lung_Opacity',\n",
       " 'COVID-19_Radiography_Dataset/Viral Pneumonia']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qoeceth32myK"
   },
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "x = GlobalMaxPooling2D()(vgg16.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qIv9WgYn2myK"
   },
   "outputs": [],
   "source": [
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiyPQpQg2myL",
    "outputId": "2df27900-8b56-4891-ee96-d3bd094a8d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 14,780,868\n",
      "Trainable params: 66,180\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ehy5jeSp2myL"
   },
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy', tf.keras.metrics.Recall(name='Recall'),\\\n",
    "                                 tf.keras.metrics.Precision(name='Precision'), \n",
    "                    tf.keras.metrics.AUC(\n",
    "        num_thresholds=200,\n",
    "        curve=\"ROC\",\n",
    "        summation_method=\"interpolation\",\n",
    "        name=\"AUC\",\n",
    "        dtype=None,\n",
    "        thresholds=None,\n",
    "        multi_label=True,\n",
    "        label_weights=None,\n",
    "    )]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7Sj1VTPR2myL"
   },
   "outputs": [],
   "source": [
    "# Use the Image Data Generator to import the images from the dataset\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "584vgGBG2myM",
    "outputId": "0579b31a-389f-4a54-c01a-a2254fc33fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16933 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you provide the same target size as initialied for the image size\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-ggWfPI2myM",
    "outputId": "0812aa2d-3e86-4743-9dce-7ba9c32eb5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4232 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = train_datagen.flow_from_directory(train_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_AUC', factor=0.1, patience=3, verbose=1, mode='max',\n",
    "    min_delta=0.0001, cooldown=0, min_lr=0\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_5Yb5Un2myN",
    "outputId": "e36d8e2c-bb8e-499d-ddbe-78c5507e2e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 148s 137ms/step - loss: 0.8636 - accuracy: 0.6476 - Recall: 0.5313 - Precision: 0.7257 - AUC: 0.8262 - val_loss: 0.6018 - val_accuracy: 0.7765 - val_Recall: 0.7169 - val_Precision: 0.8080 - val_AUC: 0.9291\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 145s 137ms/step - loss: 0.6230 - accuracy: 0.7583 - Recall: 0.7018 - Precision: 0.7946 - AUC: 0.9164 - val_loss: 0.5335 - val_accuracy: 0.8006 - val_Recall: 0.7606 - val_Precision: 0.8329 - val_AUC: 0.9448\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 146s 138ms/step - loss: 0.5625 - accuracy: 0.7825 - Recall: 0.7414 - Precision: 0.8139 - AUC: 0.9313 - val_loss: 0.5457 - val_accuracy: 0.7869 - val_Recall: 0.7495 - val_Precision: 0.8110 - val_AUC: 0.9462\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 146s 137ms/step - loss: 0.5355 - accuracy: 0.7915 - Recall: 0.7574 - Precision: 0.8236 - AUC: 0.9378 - val_loss: 0.5175 - val_accuracy: 0.8051 - val_Recall: 0.7734 - val_Precision: 0.8301 - val_AUC: 0.9471\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 143s 135ms/step - loss: 0.5432 - accuracy: 0.7903 - Recall: 0.7530 - Precision: 0.8191 - AUC: 0.9353 - val_loss: 0.4607 - val_accuracy: 0.8233 - val_Recall: 0.7937 - val_Precision: 0.8476 - val_AUC: 0.9552\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 144s 136ms/step - loss: 0.5208 - accuracy: 0.7987 - Recall: 0.7644 - Precision: 0.8254 - AUC: 0.9400 - val_loss: 0.4791 - val_accuracy: 0.8152 - val_Recall: 0.7866 - val_Precision: 0.8413 - val_AUC: 0.9531\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 146s 138ms/step - loss: 0.5128 - accuracy: 0.8033 - Recall: 0.7700 - Precision: 0.8274 - AUC: 0.9416 - val_loss: 0.4584 - val_accuracy: 0.8233 - val_Recall: 0.8020 - val_Precision: 0.8393 - val_AUC: 0.9544\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 145s 137ms/step - loss: 0.4968 - accuracy: 0.8136 - Recall: 0.7851 - Precision: 0.8373 - AUC: 0.9436 - val_loss: 0.4760 - val_accuracy: 0.8121 - val_Recall: 0.7812 - val_Precision: 0.8334 - val_AUC: 0.9552\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 144s 136ms/step - loss: 0.4713 - accuracy: 0.8155 - Recall: 0.7832 - Precision: 0.8387 - AUC: 0.9510 - val_loss: 0.4440 - val_accuracy: 0.8374 - val_Recall: 0.8147 - val_Precision: 0.8564 - val_AUC: 0.9576\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 144s 136ms/step - loss: 0.4386 - accuracy: 0.8359 - Recall: 0.8088 - Precision: 0.8550 - AUC: 0.9562 - val_loss: 0.4302 - val_accuracy: 0.8334 - val_Recall: 0.8145 - val_Precision: 0.8517 - val_AUC: 0.9604\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "# Run the cell. It will take some time to execute\n",
    "r = model.fit(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set),\n",
    "  callbacks=[reduce_lr,early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 28s 107ms/step\n"
     ]
    }
   ],
   "source": [
    "test_set.reset()\n",
    "Y_pred = model.predict(test_set, verbose = 1)\n",
    "\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KrVRE3cS2myR"
   },
   "outputs": [],
   "source": [
    "y_true = test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3428638941398866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Transfer Learning VGG16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

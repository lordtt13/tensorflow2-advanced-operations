{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross-Lingual Similarity and Semantic Search Engine.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbFhLbU52abn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import bokeh\n",
        "import bokeh.models\n",
        "import bokeh.plotting\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import sklearn.metrics.pairwise\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "from simpleneighbors import SimpleNeighbors\n",
        "from tensorflow_text import SentencepieceTokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXCVRZ8l2o3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_similarity(embeddings_1, embeddings_2, labels_1, labels_2,\n",
        "                         plot_title,\n",
        "                         plot_width = 1200, plot_height = 600,\n",
        "                         xaxis_font_size = '12pt', yaxis_font_size = '12pt'):\n",
        "\n",
        "  assert len(embeddings_1) == len(labels_1)\n",
        "  assert len(embeddings_2) == len(labels_2)\n",
        "\n",
        "  # arccos based text similarity (Yang et al. 2019; Cer et al. 2019)\n",
        "  sim = 1 - np.arccos(\n",
        "      sklearn.metrics.pairwise.cosine_similarity(embeddings_1,\n",
        "                                                 embeddings_2))/np.pi\n",
        "\n",
        "  embeddings_1_col, embeddings_2_col, sim_col = [], [], []\n",
        "  for i in range(len(embeddings_1)):\n",
        "    for j in range(len(embeddings_2)):\n",
        "      embeddings_1_col.append(labels_1[i])\n",
        "      embeddings_2_col.append(labels_2[j])\n",
        "      sim_col.append(sim[i][j])\n",
        "\n",
        "  df = pd.DataFrame(zip(embeddings_1_col, embeddings_2_col, sim_col),\n",
        "                    columns = ['embeddings_1', 'embeddings_2', 'sim'])\n",
        "\n",
        "  mapper = bokeh.models.LinearColorMapper(\n",
        "      palette = [*reversed(bokeh.palettes.YlOrRd[9])], low = df.sim.min(),\n",
        "      high = df.sim.max())\n",
        "\n",
        "  p = bokeh.plotting.figure(title = plot_title, x_range = labels_1,\n",
        "                            x_axis_location = \"above\",\n",
        "                            y_range = [*reversed(labels_2)],\n",
        "                            plot_width = plot_width, plot_height = plot_height,\n",
        "                            tools = \"save\",toolbar_location = 'below', tooltips = [\n",
        "                                ('pair', '@embeddings_1 ||| @embeddings_2'),\n",
        "                                ('sim', '@sim')])\n",
        "  p.rect(x = \"embeddings_1\", y = \"embeddings_2\", width = 1, height = 1, source = df,\n",
        "         fill_color = {'field': 'sim', 'transform': mapper}, line_color = None)\n",
        "\n",
        "  p.title.text_font_size = '12pt'\n",
        "  p.axis.axis_line_color = None\n",
        "  p.axis.major_tick_line_color = None\n",
        "  p.axis.major_label_standoff = 16\n",
        "  p.xaxis.major_label_text_font_size = xaxis_font_size\n",
        "  p.xaxis.major_label_orientation = 0.25 * np.pi\n",
        "  p.yaxis.major_label_text_font_size = yaxis_font_size\n",
        "  p.min_border_right = 300\n",
        "\n",
        "  bokeh.io.output_notebook()\n",
        "  bokeh.io.show(p)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCHM5cwY3Nr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = 'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3'\n",
        "\n",
        "model = hub.load(module_url)\n",
        "\n",
        "def embed_text(input):\n",
        "  return model(input)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr3YqDo33aZa",
        "colab_type": "text"
      },
      "source": [
        "### Computing Text Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqZyQlCy3ctw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some texts of different lengths in different languages.\n",
        "arabic_sentences = ['كلب', 'الجراء لطيفة.', 'أستمتع بالمشي لمسافات طويلة على طول الشاطئ مع كلبي.']\n",
        "chinese_sentences = ['狗', '小狗很好。', '我喜欢和我的狗一起沿着海滩散步。']\n",
        "english_sentences = ['dog', 'Puppies are nice.', 'I enjoy taking long walks along the beach with my dog.']\n",
        "french_sentences = ['chien', 'Les chiots sont gentils.', 'J\\'aime faire de longues promenades sur la plage avec mon chien.']\n",
        "german_sentences = ['Hund', 'Welpen sind nett.', 'Ich genieße lange Spaziergänge am Strand entlang mit meinem Hund.']\n",
        "italian_sentences = ['cane', 'I cuccioli sono carini.', 'Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.']\n",
        "japanese_sentences = ['犬', '子犬はいいです', '私は犬と一緒にビーチを散歩するのが好きです']\n",
        "korean_sentences = ['개', '강아지가 좋다.', '나는 나의 산책을 해변을 따라 길게 산책하는 것을 즐긴다.']\n",
        "russian_sentences = ['собака', 'Милые щенки.', 'Мне нравится подолгу гулять по пляжу со своей собакой.']\n",
        "spanish_sentences = ['perro', 'Los cachorros son agradables.', 'Disfruto de dar largos paseos por la playa con mi perro.']\n",
        "\n",
        "# Multilingual example\n",
        "multilingual_example = [\"Willkommen zu einfachen, aber\", \"verrassend krachtige\", \"multilingüe\", \"compréhension du langage naturel\", \"модели.\", \"大家是什么意思\" , \"보다 중요한\", \".اللغة التي يتحدثونها\"]\n",
        "multilingual_example_in_en =  [\"Welcome to simple yet\", \"surprisingly powerful\", \"multilingual\", \"natural language understanding\", \"models.\", \"What people mean\", \"matters more than\", \"the language they speak.\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkoWqbcS3hkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute embeddings.\n",
        "ar_result = embed_text(arabic_sentences)\n",
        "en_result = embed_text(english_sentences)\n",
        "es_result = embed_text(spanish_sentences)\n",
        "de_result = embed_text(german_sentences)\n",
        "fr_result = embed_text(french_sentences)\n",
        "it_result = embed_text(italian_sentences)\n",
        "ja_result = embed_text(japanese_sentences)\n",
        "ko_result = embed_text(korean_sentences)\n",
        "ru_result = embed_text(russian_sentences)\n",
        "zh_result = embed_text(chinese_sentences)\n",
        "\n",
        "multilingual_result = embed_text(multilingual_example)\n",
        "multilingual_in_en_result = embed_text(multilingual_example_in_en)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4KmAZSu3lNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import annoy\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "from apache_beam.transforms import util\n",
    "from sklearn.random_projection import gaussian_random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.1.0\n",
      "TF-Hub version: 0.8.0\n",
      "Apache Beam version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "print('TF version: {}'.format(tf.__version__))\n",
    "print('TF-Hub version: {}'.format(hub.__version__))\n",
    "print('Apache Beam version: {}'.format(beam.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Million News Headlines dataset contains news headlines published over a period of 15 years sourced from the reputable Australian Broadcasting Corp. (ABC). This news dataset has a summarised historical record of noteworthy events in the globe from early-2003 to end-2017 with a more granular focus on Australia.\n",
    "\n",
    "Format: Tab-separated two-column data: 1) publication date and 2) headline text. We are only interested in the headline text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_date\theadline_text\r\n",
      "20030219\t\"aba decides against community broadcasting licence\"\r\n",
      "20030219\t\"act fire witnesses must be aware of defamation\"\r\n",
      "20030219\t\"a g calls for infrastructure protection summit\"\r\n",
      "20030219\t\"air nz staff in aust strike for pay rise\"\r\n",
      "20030219\t\"air nz strike to affect australian travellers\"\r\n",
      "20030219\t\"ambitious olsson wins triple jump\"\r\n",
      "20030219\t\"antic delighted with record breaking barca\"\r\n",
      "20030219\t\"aussie qualifier stosur wastes four memphis match\"\r\n",
      "20030219\t\"aust addresses un security council over iraq\"\r\n"
     ]
    }
   ],
   "source": [
    "!head raw.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only keep the headline\n",
    "\n",
    "!rm -r corpus\n",
    "!mkdir corpus\n",
    "\n",
    "with open('corpus/text.txt', 'w') as out_file:\n",
    "  with open('raw.tsv', 'r') as in_file:\n",
    "    for line in in_file:\n",
    "      headline = line.split('\\t')[1].strip().strip('\"')\n",
    "      out_file.write(headline+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severe storms forecast for nye in south east queensland\r\n",
      "snake catcher pleads for people not to kill reptiles\r\n",
      "south australia prepares for party to welcome new year\r\n",
      "strikers cool off the heat with big win in adelaide\r\n",
      "stunning images from the sydney to hobart yacht\r\n",
      "the ashes smiths warners near miss liven up boxing day test\r\n",
      "timelapse: brisbanes new year fireworks\r\n",
      "what 2017 meant to the kids of australia\r\n",
      "what the papodopoulos meeting may mean for ausus\r\n",
      "who is george papadopoulos the former trump campaign aide\r\n"
     ]
    }
   ],
   "source": [
    "!tail corpus/text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding extraction method\n",
    "\n",
    "embed_fn = None\n",
    "\n",
    "def generate_embeddings(text, module_url, random_projection_matrix = None):\n",
    "  # Beam will run this function in different processes that need to\n",
    "  # import hub and load embed_fn (if not previously loaded)\n",
    "  global embed_fn\n",
    "  if embed_fn is None:\n",
    "    embed_fn = hub.load(module_url)\n",
    "  embedding = embed_fn(text).numpy()\n",
    "  if random_projection_matrix is not None:\n",
    "    embedding = embedding.dot(random_projection_matrix)\n",
    "  return text, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_example(entries):\n",
    "  examples = []\n",
    "\n",
    "  text_list, embedding_list = entries\n",
    "  for i in range(len(text_list)):\n",
    "    text = text_list[i]\n",
    "    embedding = embedding_list[i]\n",
    "\n",
    "    features = {\n",
    "        'text': tf.train.Feature(\n",
    "            bytes_list = tf.train.BytesList(value = [text.encode('utf-8')])),\n",
    "        'embedding': tf.train.Feature(\n",
    "            float_list = tf.train.FloatList(value = embedding.tolist()))\n",
    "    }\n",
    "  \n",
    "    example = tf.train.Example(\n",
    "        features = tf.train.Features(\n",
    "            feature = features)).SerializeToString(deterministic = True)\n",
    "  \n",
    "    examples.append(example)\n",
    "  \n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam Pipeline\n",
    "\n",
    "def run_hub2emb(args):\n",
    "  '''Runs the embedding generation pipeline'''\n",
    "\n",
    "  options = beam.options.pipeline_options.PipelineOptions(**args)\n",
    "  args = namedtuple(\"options\", args.keys())(*args.values())\n",
    "\n",
    "  with beam.Pipeline(args.runner, options = options) as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | 'Read sentences from files' >> beam.io.ReadFromText(\n",
    "            file_pattern = args.data_dir)\n",
    "        | 'Batch elements' >> util.BatchElements(\n",
    "            min_batch_size = args.batch_size, max_batch_size = args.batch_size)\n",
    "        | 'Generate embeddings' >> beam.Map(\n",
    "            generate_embeddings, args.module_url, args.random_projection_matrix)\n",
    "        | 'Encode to tf example' >> beam.FlatMap(to_tf_example)\n",
    "        | 'Write to TFRecords files' >> beam.io.WriteToTFRecord(\n",
    "            file_path_prefix = '{}/emb'.format(args.output_dir),\n",
    "            file_name_suffix = '.tfrecords')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random projection is a simple, yet powerfull technique used to reduce the dimensionality of a set of points which lie in Euclidean space. For a theoretical background, see the Johnson-Lindenstrauss lemma.\n",
    "\n",
    "Reducing the dimensionality of the embeddings with random projection means less time needed to build and query the ANN index.\n",
    "\n",
    "In this tutorial we use Gaussian Random Projection from the Scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_projection_weights(original_dim, projected_dim):\n",
    "  random_projection_matrix = None\n",
    "  random_projection_matrix = gaussian_random_matrix(\n",
    "      n_components = projected_dim, n_features = original_dim).T\n",
    "  print(\"A Gaussian random weight matrix was creates with shape of {}\".format(random_projection_matrix.shape))\n",
    "  print('Storing random projection matrix to disk...')\n",
    "  with open('random_projection_matrix', 'wb') as handle:\n",
    "    pickle.dump(random_projection_matrix, \n",
    "                handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "  return random_projection_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

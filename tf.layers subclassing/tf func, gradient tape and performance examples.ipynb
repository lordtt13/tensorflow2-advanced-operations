{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 2.0, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability.\n",
    "\n",
    "To get peak performance and to make your model deployable anywhere, use tf.function to make graphs out of our programs. Thanks to AutoGraph, a surprising amount of Python code just works with tf.function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "# Some helper code to demonstrate the kinds of errors we might encounter.\n",
    "@contextlib.contextmanager\n",
    "def assert_raises(error_class):\n",
    "  try:\n",
    "    yield\n",
    "  except error_class as e:\n",
    "    print('Caught expected exception \\n  {}:'.format(error_class))\n",
    "    traceback.print_exc(limit=2)\n",
    "  except Exception as e:\n",
    "    raise e\n",
    "  else:\n",
    "    raise Exception('Expected {} to be raised but no error was raised!'.format(\n",
    "        error_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf.function we define is just like a core TensorFlow operation: We can execute it eagerly; we can use it in a graph; it has gradients; and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions inside functions\n",
    "\n",
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "  return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing and polymorphism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"a:0\", shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "\n",
      "Tracing with Tensor(\"a:0\", shape=(), dtype=string)\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Functions are polymorphic\n",
    "\n",
    "@tf.function\n",
    "def double(a):\n",
    "  print(\"Tracing with\", a)\n",
    "  return a + a\n",
    "\n",
    "print(double(tf.constant(1)))\n",
    "print()\n",
    "print(double(tf.constant(1.1)))\n",
    "print()\n",
    "print(double(tf.constant(\"a\")))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow graphs require static dtypes and shape dimensions. tf.function bridges this gap by retracing the function when necessary to generate the correct graphs.\n",
    "\n",
    "To control the tracing behavior, use the following techniques:<br/>\n",
    "Create a new tf.function. Separate tf.function objects are guaranteed not to share traces.<br/>\n",
    "Use the get_concrete_function method to get a specific trace <br/>\n",
    "Specify input_signature when calling tf.function to trace only once per calling graph. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining concrete trace\n",
      "Tracing with Tensor(\"a:0\", dtype=string)\n",
      "Executing traced function\n",
      "tf.Tensor(b'aa', shape=(), dtype=string)\n",
      "tf.Tensor(b'bb', shape=(), dtype=string)\n",
      "Using a concrete trace with incompatible types will throw an error\n",
      "Caught expected exception \n",
      "  <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-7-9ec6a3609b01>\", line 8, in <module>\n",
      "    double_strings(tf.constant(1))\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute __inference_double_87 as input #0(zero-based) was expected to be a string tensor but is a int32 tensor [Op:__inference_double_87]\n"
     ]
    }
   ],
   "source": [
    "print(\"Obtaining concrete trace\")\n",
    "double_strings = double.get_concrete_function(tf.TensorSpec(shape = None, dtype = tf.string))\n",
    "print(\"Executing traced function\")\n",
    "print(double_strings(tf.constant(\"a\")))\n",
    "print(double_strings(a = tf.constant(\"b\")))\n",
    "print(\"Using a concrete trace with incompatible types will throw an error\")\n",
    "with assert_raises(tf.errors.InvalidArgumentError):\n",
    "  double_strings(tf.constant(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"x:0\", shape=(None,), dtype=int32)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int32)\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-8-5726fffa431b>\", line 9, in <module>\n",
      "    next_collatz(tf.constant([[1, 2], [3, 4]]))\n",
      "ValueError: Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature = (tf.TensorSpec(shape = [None], dtype = tf.int32),))\n",
    "def next_collatz(x):\n",
    "  print(\"Tracing with\", x)\n",
    "  return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
    "\n",
    "print(next_collatz(tf.constant([1, 2])))\n",
    "# We specified a 1-D tensor in the input signature, so this should fail.\n",
    "with assert_raises(ValueError):\n",
    "  next_collatz(tf.constant([[1, 2], [3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A polymorphic tf.function keeps a cache of concrete functions generated by tracing. The cache keys are effectively tuples of keys generated from the function args and kwargs. The key generated for a tf.Tensor argument is its number of dimensions and type. The key generated for a Python primitive is its value. For all other Python types, the keys are based on the object id() so that methods are traced independently for each instance of a class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, Python arguments are used to control hyperparameters and graph constructions - for example, num_layers = 10 or training = True or nonlinearity = 'relu'. So if the Python argument changes, it makes sense that you'd have to retrace the graph.\n",
    "\n",
    "However, it's possible that a Python argument is not being used to control graph construction. In these cases, a change in the Python value can trigger needless retracing. Take, for example, this training loop, which AutoGraph will dynamically unroll. Despite the multiple traces, the generated graph is actually identical, so this is a bit inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = 10\n",
      "Tracing with num_steps = 20\n"
     ]
    }
   ],
   "source": [
    "def train_one_step():\n",
    "  pass\n",
    "\n",
    "@tf.function\n",
    "def train(num_steps):\n",
    "  print(\"Tracing with num_steps = {}\".format(num_steps))\n",
    "  for _ in tf.range(num_steps):\n",
    "    train_one_step()\n",
    "\n",
    "train(num_steps = 10)\n",
    "train(num_steps = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with num_steps = Tensor(\"num_steps:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# The simple workaround here is to cast your arguments to Tensors if they do not affect the shape of the generated graph.\n",
    "\n",
    "train(num_steps = tf.constant(10))\n",
    "train(num_steps = tf.constant(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general rule of thumb is to only use Python side effects to debug your traces. Otherwise, TensorFlow ops like tf.Variable.assign, tf.print, and tf.summary are the best way to ensure your code will be traced and executed by the TensorFlow runtime with each call. In general using a functional style will yield the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced with 1\n",
      "Executed with 1\n",
      "Executed with 1\n",
      "Traced with 2\n",
      "Executed with 2\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  print(\"Traced with\", x)\n",
    "  tf.print(\"Executed with\", x)\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to execute Python code during each invocation of a tf.function, tf.py_function is an exit hatch. The drawback of tf.py_function is that it's not portable or particularly performant, nor does it work well in distributed (multi-GPU, TPU) setups. Also, since tf.py_function has to be wired into the graph for differentiability, it casts all inputs/outputs to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python side effect\n",
      "Python side effect\n",
      "Python side effect\n"
     ]
    }
   ],
   "source": [
    "external_list = []\n",
    "\n",
    "def side_effect(x):\n",
    "  print('Python side effect')\n",
    "  external_list.append(x)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  tf.py_function(side_effect, inp = [x], Tout = [])\n",
    "\n",
    "f(1)\n",
    "f(1)\n",
    "f(1)\n",
    "assert len(external_list) == 3\n",
    "# .numpy() call required because py_function casts 1 to tf.constant(1)\n",
    "assert external_list[0].numpy() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many Python features, such as generators and iterators, rely on the Python runtime to keep track of state. In general, while these constructs work as expected in Eager mode, many unexpected things can happen inside a tf.function due to tracing behavior.\n",
    "\n",
    "To give one example, advancing iterator state is a Python side effect and therefore only happens during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of external_var: 0\n",
      "Value of external_var: 0\n",
      "Value of external_var: 0\n"
     ]
    }
   ],
   "source": [
    "external_var = tf.Variable(0)\n",
    "@tf.function\n",
    "def buggy_consume_next(iterator):\n",
    "  external_var.assign_add(next(iterator))\n",
    "  tf.print(\"Value of external_var:\", external_var)\n",
    "\n",
    "iterator = iter([0, 1, 2, 3])\n",
    "buggy_consume_next(iterator)\n",
    "# This reuses the first value from the iterator, rather than consuming the next value.\n",
    "buggy_consume_next(iterator)\n",
    "buggy_consume_next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an iterator is generated and consumed entirely within the tf.function, then it should work correctly. However, the entire iterator is probably being traced, which can lead to a giant graph. This may be what you want. But if you're training on an large in-memory dataset represented as a Python list, then this can generate a very large graph, and tf.function is unlikely to yield a speedup.\n",
    "\n",
    "If you want to iterate over Python data, the safest way is to wrap it in a tf.data.Dataset and use the for x in y idiom. AutoGraph has special support for safely converting for loops when y is a tensor or tf.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train([(1, 1), (1, 1)]) contains 8 nodes in its graph\n",
      "train([(1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]) contains 32 nodes in its graph\n",
      "train(<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 9 nodes in its graph\n",
      "train(<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>) contains 9 nodes in its graph\n"
     ]
    }
   ],
   "source": [
    "def measure_graph_size(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  print(\"{}({}) contains {} nodes in its graph\".format(\n",
    "      f.__name__, ', '.join(map(str, args)), len(g.as_graph_def().node)))\n",
    "\n",
    "@tf.function\n",
    "def train(dataset):\n",
    "  loss = tf.constant(0)\n",
    "  for x, y in dataset:\n",
    "    loss += tf.abs(y - x) # Some dummy computation.\n",
    "  return loss\n",
    "\n",
    "small_data = [(1, 1)] * 2\n",
    "big_data = [(1, 1)] * 10\n",
    "measure_graph_size(train, small_data)\n",
    "measure_graph_size(train, big_data)\n",
    "\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: small_data, (tf.int32, tf.int32)))\n",
    "measure_graph_size(train, tf.data.Dataset.from_generator(\n",
    "    lambda: big_data, (tf.int32, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wrapping Python/Numpy data in a Dataset, be mindful of tf.data.Dataset.from_generator versus tf.data.Dataset.from_tensors. The former will keep the data in Python and fetch it via tf.py_function which can have performance implications, whereas the latter will bundle a copy of the data as one large tf.constant() node in the graph, which can have memory implications.\n",
    "\n",
    "Reading data from files via TFRecordDataset/CsvDataset/etc. is the most effective way to consume data, as then TensorFlow itself can manage the asynchronous loading and prefetching of data, without having to involve Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Control Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "  a.assign(y * b)\n",
    "  tf.print(a)\n",
    "  b.assign_add(x * a)\n",
    "  tf.print(b)\n",
    "  return a + b\n",
    "\n",
    "f(1.0, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "Due to tracing semantics, tf.function will reuse the same variable each call, but eager mode will create a new variable with each call. To guard against this mistake, tf.function will raise an error if it detects dangerous variable creation behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-16-73e410646579>\", line 8, in <module>\n",
      "    f(1.0)\n",
      "ValueError: in converted code:\n",
      "\n",
      "    <ipython-input-16-73e410646579>:3 f  *\n",
      "        v = tf.Variable(1.0)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:260 __call__\n",
      "        return cls._variable_v2_call(*args, **kwargs)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:254 _variable_v2_call\n",
      "        shape=shape)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:65 getter\n",
      "        return captured_getter(captured_previous, **kwargs)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:502 invalid_creator_scope\n",
      "        \"tf.function-decorated function tried to create \"\n",
      "\n",
      "    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  v = tf.Variable(1.0)\n",
    "  v.assign_add(x)\n",
    "  return v\n",
    "\n",
    "with assert_raises(ValueError):\n",
    "  f(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-ambiguous code is ok, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  return v.assign_add(x)\n",
    "\n",
    "tf.print(f(1.0))  \n",
    "tf.print(f(2.0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create variables inside a tf.function as long as we can prove that those variables are created only the first time the function is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "class C:\n",
    "  pass\n",
    "\n",
    "obj = C()\n",
    "obj.v = None\n",
    "\n",
    "@tf.function\n",
    "def g(x):\n",
    "  if obj.v is None:\n",
    "    obj.v = tf.Variable(1.0)\n",
    "  return obj.v.assign_add(x)\n",
    "\n",
    "tf.print(g(1.0))   \n",
    "tf.print(g(2.0))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable initializers can depend on function arguments and on values of other variables. We can figure out the right initialization order using the same method we use to generate control dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.0, shape=(), dtype=float32)\n",
      "tf.Tensor(36.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "state = []\n",
    "@tf.function\n",
    "def fn(x):\n",
    "  if not state:\n",
    "    state.append(tf.Variable(2.0 * x))\n",
    "    state.append(tf.Variable(state[0] * 3.0))\n",
    "  return state[0] * x * state[1]\n",
    "\n",
    "print(fn(tf.constant(1.0)))\n",
    "print(fn(tf.constant(3.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AutoGraph\n",
    "\n",
    "The autograph library is fully integrated with tf.function, and it will rewrite conditionals and loops which depend on Tensors to run dynamically in the graph.\n",
    "\n",
    "tf.cond and tf.while_loop continue to work with tf.function, but code with control flow is often easier to write and understand when written in imperative style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9854635 0.779349566 0.620462418 0.308074117 0.543499112]\n",
      "[0.755421281 0.6523332 0.551449895 0.298684031 0.495632082]\n",
      "[0.638372064 0.573238492 0.501606107 0.290107846 0.458675086]\n",
      "[0.563790083 0.517733693 0.463379323 0.282234073 0.429003775]\n",
      "[0.510784149 0.47594896 0.432834446 0.274971485 0.404488415]\n",
      "[0.470555931 0.442993402 0.407687396 0.268244714 0.383782864]\n",
      "[0.438648403 0.416122615 0.386507332 0.261990786 0.365988165]\n",
      "[0.412523508 0.393658936 0.36834532 0.256156623 0.350477636]\n",
      "[0.390613258 0.374510288 0.352543533 0.250697196 0.336799055]\n",
      "[0.371888787 0.357930511 0.338629335 0.245573923 0.32461673]\n",
      "[0.355642706 0.343389869 0.326253176 0.240753591 0.313675404]\n",
      "[0.341370255 0.330500364 0.315150082 0.236207426 0.303777039]\n",
      "[0.328700155 0.318970293 0.305115 0.231910318 0.294765294]\n",
      "[0.317352325 0.308575541 0.295986533 0.227840289 0.286514848]\n",
      "[0.307110906 0.299140662 0.287635446 0.223977983 0.278923929]\n",
      "[0.297806501 0.290526 0.279957026 0.220306277 0.271908849]\n",
      "[0.289303958 0.28261885 0.272865295 0.216809958 0.265400112]\n",
      "[0.281494051 0.275327146 0.266288966 0.213475481 0.259339452]\n",
      "[0.274287283 0.268574744 0.260168344 0.2102907 0.253677607]\n",
      "[0.267609626 0.262298137 0.254452974 0.207244739 0.24837254]\n",
      "[0.26139918 0.256443799 0.24909994 0.204327762 0.243388221]\n",
      "[0.25560376 0.250966311 0.244072407 0.201530918 0.238693506]\n",
      "[0.250179 0.245826796 0.239338607 0.198846161 0.234261334]\n",
      "[0.245086908 0.240991801 0.23487094 0.196266189 0.230068058]\n",
      "[0.240294755 0.236432329 0.230645329 0.193784341 0.226092935]\n",
      "[0.235774145 0.232123122 0.226640627 0.191394553 0.222317636]\n",
      "[0.231500298 0.228042036 0.222838193 0.18909125 0.218725935]\n",
      "[0.227451518 0.224169597 0.219221532 0.186869338 0.215303391]\n",
      "[0.223608688 0.220488578 0.215775967 0.184724137 0.212037116]\n",
      "[0.219954878 0.216983691 0.212488398 0.182651311 0.208915532]\n",
      "[0.216475055 0.213641286 0.209347084 0.180646881 0.205928251]\n",
      "[0.213155821 0.210449174 0.206341475 0.178707168 0.203065902]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.20998517, 0.2073964 , 0.20346205, 0.17682876, 0.20031999],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "f(tf.random.uniform([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__f(x):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('f', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "\n",
      "    def get_state():\n",
      "      return ()\n",
      "\n",
      "    def set_state(_):\n",
      "      pass\n",
      "\n",
      "    def loop_body(x):\n",
      "      ag__.converted_call(tf.print, (x,), None, fscope)\n",
      "      x = ag__.converted_call(tf.tanh, (x,), None, fscope)\n",
      "      return x,\n",
      "\n",
      "    def loop_test(x):\n",
      "      return ag__.converted_call(tf.reduce_sum, (x,), None, fscope) > 1\n",
      "    x, = ag__.while_stmt(loop_test, loop_body, get_state, set_state, (x,), ('x',), ())\n",
      "    do_return = True\n",
      "    retval_ = fscope.mark_return_value(x)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The autograph code\n",
    "\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "print(tf.autograph.to_code(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph will convert if statements into the equivalent tf.cond calls.\n",
    "\n",
    "This substitution is made if the condition is a Tensor. Otherwise, the conditional is executed during tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that checks if the resulting graph uses tf.cond\n",
    "\n",
    "def test_tf_cond(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'cond' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.cond.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) executes normally.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "\n",
    "  print(\"  result: \",f(*args).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def dropout(x, training = True):\n",
    "  if training:\n",
    "    x = tf.nn.dropout(x, rate = 0.5)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout(tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32), True) executes normally.\n",
      "  result:  [0. 0. 0. 2. 0. 0. 0. 2. 0. 2.]\n"
     ]
    }
   ],
   "source": [
    "test_tf_cond(dropout, tf.ones([10], dtype = tf.float32), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout(tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], shape=(10,), dtype=float32), tf.Tensor(True, shape=(), dtype=bool)) uses tf.cond.\n",
      "  result:  [2. 0. 0. 0. 2. 2. 2. 0. 0. 2.]\n"
     ]
    }
   ],
   "source": [
    "# But passing a tensor replaces the python if with a tf.cond\n",
    "\n",
    "test_tf_cond(dropout, tf.ones([10], dtype = tf.float32), tf.constant(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.cond has a number of subtleties.\n",
    "\n",
    "it works by tracing both sides of the conditional, and then choosing the appropriate branch at runtime, depending on the condition. Tracing both sides can result in unexpected execution of Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  if x > 0:\n",
    "    x = x + 1.\n",
    "    print(\"Tracing `then` branch\")\n",
    "  else:\n",
    "    x = x - 1.\n",
    "    print(\"Tracing `else` branch\")\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `else` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(-1.0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `then` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(1.0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `then` branch\n",
      "Tracing `else` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(tf.constant(1.0)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'ValueError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-30-42d6b34fcd01>\", line 11, in <module>\n",
      "    f()\n",
      "ValueError: in converted code:\n",
      "\n",
      "    <ipython-input-30-42d6b34fcd01>:5 f  *\n",
      "        if tf.constant(True):\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:918 if_stmt\n",
      "        basic_symbol_names, composite_symbol_names)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:956 tf_if_stmt\n",
      "        error_checking_orelse)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:507 new_func\n",
      "        return func(*args, **kwargs)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py:1174 cond\n",
      "        return cond_v2.cond_v2(pred, true_fn, false_fn, name)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/cond_v2.py:90 cond_v2\n",
      "        op_return_value=pred)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:978 func_graph_from_py_func\n",
      "        func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:949 error_checking_orelse\n",
      "        result[orelse_branch] = orelse()\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:987 wrapper\n",
      "        new_vars = func()\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1013 wrapper\n",
      "        tuple(s.symbol_name for s in undefined)))\n",
      "\n",
      "    ValueError: The following symbols must also be initialized in the else branch: ('x',). Alternatively, you may initialize them before the if statement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if one branch creates a tensor used downstream, the other branch must also create that tensor\n",
    "\n",
    "@tf.function\n",
    "def f():\n",
    "  if tf.constant(True):\n",
    "    x = tf.ones([3, 3])\n",
    "  return x\n",
    "\n",
    "# Throws an error because both branches need to define `x`.\n",
    "with assert_raises(ValueError):\n",
    "  f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to be sure that a particular section of control flow is never converted by autograph, then explicitly convert the object to a python type so an error is raised instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x, y):\n",
    "  if bool(x):\n",
    "    y = y + 1.\n",
    "    print(\"Tracing `then` branch\")\n",
    "  else:\n",
    "    y = y - 1.\n",
    "    print(\"Tracing `else` branch\")\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `then` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(True, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing `else` branch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(False, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-34-427fe80db841>\", line 2, in <module>\n",
      "    f(tf.constant(True), 0.0)\n",
      "tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in converted code:\n",
      "\n",
      "    <ipython-input-31-772984717e3d>:3 f  *\n",
      "        if bool(x):\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py:416 converted_call\n",
      "        return py_builtins.overload_of(f)(*args)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:757 __bool__\n",
      "        self._disallow_bool_casting()\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_bool_casting\n",
      "        \"using a `tf.Tensor` as a Python `bool`\")\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:510 _disallow_when_autograph_enabled\n",
      "        \" decorating it directly with @tf.function.\".format(task))\n",
      "\n",
      "    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with assert_raises(TypeError):\n",
    "  f(tf.constant(True), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph and loops\n",
    "\n",
    "AutoGraph has a few simple rules for converting loops.\n",
    "\n",
    "for: Convert if the iterable is a tensor\n",
    "while: Convert if the while condition depends on a tensor\n",
    "If a loop is converted, it will be dynamically unrolled with tf.while_loop, or in the special case of a for x in tf.data.Dataset, transformed into tf.data.Dataset.reduce.\n",
    "\n",
    "If a loop is not converted, it will be statically unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dynamically_unrolled(f, *args):\n",
    "  g = f.get_concrete_function(*args).graph\n",
    "  if any(node.name == 'while' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.while_loop.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  elif any(node.name == 'ReduceDataset' for node in g.as_graph_def().node):\n",
    "    print(\"{}({}) uses tf.data.Dataset.reduce.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))\n",
    "  else:\n",
    "    print(\"{}({}) gets unrolled.\".format(\n",
    "        f.__name__, ', '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_range() gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "# Static Unrolling\n",
    "\n",
    "@tf.function\n",
    "def for_in_range():\n",
    "  x = 0\n",
    "  for i in range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for_in_tfdataset() uses tf.data.Dataset.reduce.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def for_in_tfdataset():\n",
    "  x = tf.constant(0, dtype = tf.int64)\n",
    "  for i in tf.data.Dataset.range(5):\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(for_in_tfdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_py_cond() gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_py_cond():\n",
    "  x = 5\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_tf_cond() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_tf_cond():\n",
    "  x = tf.constant(5)\n",
    "  while x > 0:\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_tf_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_py_true_py_break(5) gets unrolled.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_py_true_py_break(x):\n",
    "  while True:  # py true\n",
    "    if x == 0: # py break\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_py_true_py_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-41-453240ea98e6>\", line 10, in <module>\n",
      "    test_dynamically_unrolled(buggy_while_py_true_tf_break, 5)\n",
      "tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in converted code:\n",
      "\n",
      "    <ipython-input-41-453240ea98e6>:3 buggy_while_py_true_tf_break  *\n",
      "        while True:   # py true\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:755 while_stmt\n",
      "        return _py_while_stmt(test, body, get_state, set_state, init_vars, opts)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:870 _py_while_stmt\n",
      "        while test(*loop_vars):\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:757 __bool__\n",
      "        self._disallow_bool_casting()\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_bool_casting\n",
      "        \"using a `tf.Tensor` as a Python `bool`\")\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:510 _disallow_when_autograph_enabled\n",
      "        \" decorating it directly with @tf.function.\".format(task))\n",
      "\n",
      "    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_while_py_true_tf_break(x):\n",
    "  while True:   # py true\n",
    "    if tf.equal(x, 0): # tf break\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  test_dynamically_unrolled(buggy_while_py_true_tf_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while_tf_true_tf_break(5) uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def while_tf_true_tf_break(x):\n",
    "  while tf.constant(True): # tf true\n",
    "    if x == 0:  # py break\n",
    "      break\n",
    "    x -= 1\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(while_tf_true_tf_break, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught expected exception \n",
      "  <class 'TypeError'>:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-2-15836fc885d8>\", line 8, in assert_raises\n",
      "    yield\n",
      "  File \"<ipython-input-43-82742b0a14d0>\", line 11, in <module>\n",
      "    test_dynamically_unrolled(buggy_py_for_tf_break)\n",
      "tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in converted code:\n",
      "\n",
      "    <ipython-input-43-82742b0a14d0>:4 buggy_py_for_tf_break  *\n",
      "        for i in range(5):  # py for\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:339 for_stmt\n",
      "        return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:348 _py_for_stmt\n",
      "        if extra_test is not None and not extra_test(*state):\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:757 __bool__\n",
      "        self._disallow_bool_casting()\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_bool_casting\n",
      "        \"using a `tf.Tensor` as a Python `bool`\")\n",
      "    /home/tanmay/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:510 _disallow_when_autograph_enabled\n",
      "        \" decorating it directly with @tf.function.\".format(task))\n",
      "\n",
      "    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def buggy_py_for_tf_break():\n",
    "  x = 0\n",
    "  for i in range(5):  # py for\n",
    "    if tf.equal(i, 3): # tf break\n",
    "      break\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "with assert_raises(TypeError):\n",
    "  test_dynamically_unrolled(buggy_py_for_tf_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_for_py_break() uses tf.while_loop.\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def tf_for_py_break():\n",
    "  x = 0\n",
    "  for i in tf.range(5): # tf for\n",
    "    if i == 3:  # py break\n",
    "      break\n",
    "    x += i\n",
    "  return x\n",
    "\n",
    "test_dynamically_unrolled(tf_for_py_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

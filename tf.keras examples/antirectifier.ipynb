{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Antirectifier Layer\n",
    "\n",
    "This example shows how to create custom layers, using the Antirectifier layer (originally proposed as a Keras example script in January 2016), an alternative to ReLU. Instead of zeroing-out the negative part of the input, it splits the negative and positive parts and returns the concatenation of the absolute value of both. This avoids loss of information, at the cost of an increase in dimensionality. To fix the dimensionality increase, we linearly combine the features back to a space of the original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Antirectifier(layers.Layer):\n",
    "    def __init__(self, initializer=\"he_normal\", **kwargs):\n",
    "        super(Antirectifier, self).__init__(**kwargs)\n",
    "        self.initializer = keras.initializers.get(initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        output_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(output_dim * 2, output_dim),\n",
    "            initializer=self.initializer,\n",
    "            name=\"kernel\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs -= tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "        pos = tf.nn.relu(inputs)\n",
    "        neg = tf.nn.relu(-inputs)\n",
    "        concatenated = tf.concat([pos, neg], axis=-1)\n",
    "        mixed = tf.matmul(concatenated, self.kernel)\n",
    "        return mixed\n",
    "\n",
    "    def get_config(self):\n",
    "        # Implement get_config to enable serialization. This is optional.\n",
    "        base_config = super(Antirectifier, self).get_config()\n",
    "        config = {\"initializer\": keras.initializers.serialize(self.initializer)}\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/20\n",
      "399/399 [==============================] - 2s 3ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.8030 - val_loss: 0.2211 - val_sparse_categorical_accuracy: 0.9428\n",
      "Epoch 2/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.1910 - sparse_categorical_accuracy: 0.9456 - val_loss: 0.2987 - val_sparse_categorical_accuracy: 0.9099\n",
      "Epoch 3/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.1421 - sparse_categorical_accuracy: 0.9606 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9676\n",
      "Epoch 4/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.2172 - val_sparse_categorical_accuracy: 0.9542\n",
      "Epoch 5/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9754 - val_loss: 0.1787 - val_sparse_categorical_accuracy: 0.9627\n",
      "Epoch 6/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.1500 - val_sparse_categorical_accuracy: 0.9683\n",
      "Epoch 7/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.1272 - val_sparse_categorical_accuracy: 0.9737\n",
      "Epoch 8/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.1506 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 9/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0634 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.1148 - val_sparse_categorical_accuracy: 0.9787\n",
      "Epoch 10/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9739\n",
      "Epoch 11/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0571 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.1579 - val_sparse_categorical_accuracy: 0.9730\n",
      "Epoch 12/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9863 - val_loss: 0.1497 - val_sparse_categorical_accuracy: 0.9768\n",
      "Epoch 13/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.1776 - val_sparse_categorical_accuracy: 0.9739\n",
      "Epoch 14/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0544 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9779\n",
      "Epoch 15/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9758\n",
      "Epoch 16/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0516 - sparse_categorical_accuracy: 0.9890 - val_loss: 0.1924 - val_sparse_categorical_accuracy: 0.9773\n",
      "Epoch 17/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0465 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9740\n",
      "Epoch 18/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0536 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.1839 - val_sparse_categorical_accuracy: 0.9800\n",
      "Epoch 19/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0469 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.1679 - val_sparse_categorical_accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.1917 - val_sparse_categorical_accuracy: 0.9792\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19631099700927734, 0.9768000245094299]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train on MNIST\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# The data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,)),\n",
    "        layers.Dense(256),\n",
    "        Antirectifier(),\n",
    "        layers.Dense(256),\n",
    "        Antirectifier(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.15)\n",
    "\n",
    "# Test the model\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multitrack MusicVAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR4wuzQpaZIz",
        "colab_type": "text"
      },
      "source": [
        "### Learning a Latent Space of Multitrack Measures\n",
        "\n",
        "MusicVAE learns a latent space of musical sequences. We apply the MusicVAE framework to single measures of multi-instrument General MIDI, a symbolic music representation that uses a standard set of 128 instrument sounds.\n",
        "\n",
        "The models in this notebook are capable of encoding and decoding single measures of up to 8 tracks, optionally conditioned on an underlying chord. Encoding transforms a single measure into a vector in a latent space, and decoding transforms a latent vector back into a measure. Both encoding and decoding are performed hierarchically, with one level operating on tracks and another operating on the notes (and choice of instrument) in each track."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5QbStJHauEi",
        "colab_type": "text"
      },
      "source": [
        "#### Env Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35i30w4Eap3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "014e3c45-eb5f-4dca-f4a9-202875da5ed4"
      },
      "source": [
        "!gsutil -q -m cp gs://download.magenta.tensorflow.org/models/music_vae/multitrack/* /content/\n",
        "!gsutil -q -m cp gs://download.magenta.tensorflow.org/soundfonts/SGM-v2.01-Sal-Guit-Bass-V1.3.sf2 /content/\n",
        "\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU magenta pyfluidsynth pretty_midi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 1.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 24.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 20.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 21.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3MB 23.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 31.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 28.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 10.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 22.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 41.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 307kB 42.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 21.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 655kB 41.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 27.9MB/s \n",
            "\u001b[?25h  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.11.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nqa-1XVa024",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ctypes.util\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return ctypes.util.find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRtn3upGbJHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import magenta.music as mm\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from google.colab import files\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.music.sequences_lib import concatenate_sequences\n",
        "from magenta.models.music_vae.trained_model import TrainedModel"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTmb_RXHbUM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "edd68a1a-09a0-4d62-f3e2-d9ff8b709e36"
      },
      "source": [
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjGe0m3kbWNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "Z_SIZE = 512\n",
        "TOTAL_STEPS = 512\n",
        "BAR_SECONDS = 2.0\n",
        "CHORD_DEPTH = 49\n",
        "\n",
        "SAMPLE_RATE = 44100\n",
        "SF2_PATH = '/content/SGM-v2.01-Sal-Guit-Bass-V1.3.sf2'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giZGbvNQbbk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Play sequence using SoundFont.\n",
        "def play(note_sequences):\n",
        "  if not isinstance(note_sequences, list):\n",
        "    note_sequences = [note_sequences]\n",
        "  for ns in note_sequences:\n",
        "    mm.play_sequence(ns, synth = mm.fluidsynth, sf2_path = SF2_PATH)\n",
        "  \n",
        "# Spherical linear interpolation.\n",
        "def slerp(p0, p1, t):\n",
        "  \"\"\"Spherical linear interpolation.\"\"\"\n",
        "  omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)), np.squeeze(p1/np.linalg.norm(p1))))\n",
        "  so = np.sin(omega)\n",
        "  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
        "\n",
        "# Download sequence.\n",
        "def download(note_sequence, filename):\n",
        "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "\n",
        "# Chord encoding tensor.\n",
        "def chord_encoding(chord):\n",
        "  index = mm.TriadChordOneHotEncoding().encode_event(chord)\n",
        "  c = np.zeros([TOTAL_STEPS, CHORD_DEPTH])\n",
        "  c[0,0] = 1.0\n",
        "  c[1:,index] = 1.0\n",
        "  return c\n",
        "\n",
        "# Trim sequences to exactly one bar.\n",
        "def trim_sequences(seqs, num_seconds = BAR_SECONDS):\n",
        "  for i in range(len(seqs)):\n",
        "    seqs[i] = mm.extract_subsequence(seqs[i], 0.0, num_seconds)\n",
        "    seqs[i].total_time = num_seconds\n",
        "\n",
        "# Consolidate instrument numbers by MIDI program.\n",
        "def fix_instruments_for_concatenation(note_sequences):\n",
        "  instruments = {}\n",
        "  for i in range(len(note_sequences)):\n",
        "    for note in note_sequences[i].notes:\n",
        "      if not note.is_drum:\n",
        "        if note.program not in instruments:\n",
        "          if len(instruments) >= 8:\n",
        "            instruments[note.program] = len(instruments) + 2\n",
        "          else:\n",
        "            instruments[note.program] = len(instruments) + 1\n",
        "        note.instrument = instruments[note.program]\n",
        "      else:\n",
        "        note.instrument = 9"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC0QO6uqbsp2",
        "colab_type": "text"
      },
      "source": [
        "#### Chord-Conditioned Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIGRq5ribuCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "afdfca7a-d76f-44d0-c7c3-c3b639eb8c7b"
      },
      "source": [
        "config = configs.CONFIG_MAP['hier-multiperf_vel_1bar_med_chords']\n",
        "model = TrainedModel(\n",
        "    config, batch_size = BATCH_SIZE,\n",
        "    checkpoint_dir_or_path = '/content/model_chords_fb64.ckpt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Building MusicVAE model with HierarchicalLstmEncoder, HierarchicalLstmDecoder, and hparams:\n",
            "{'max_seq_len': 512, 'z_size': 512, 'free_bits': 0.0, 'max_beta': 1.0, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [512, 512, 512], 'enc_rnn_size': [1024], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
            "INFO:tensorflow:\n",
            "Hierarchical Encoder:\n",
            "  input length: 512\n",
            "  level lengths: [64, 8]\n",
            "\n",
            "INFO:tensorflow:Level 0 splits: 8\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [1024]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/magenta/models/music_vae/lstm_utils.py:39: MultiRNNCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "INFO:tensorflow:Level 1 splits: 1\n",
            "INFO:tensorflow:\n",
            "Encoder Cells (bidirectional):\n",
            "  units: [1024]\n",
            "\n",
            "INFO:tensorflow:\n",
            "Hierarchical Decoder:\n",
            "  input length: 512\n",
            "  level output lengths: [8, 64]\n",
            "\n",
            "INFO:tensorflow:\n",
            "Decoder Cells:\n",
            "  units: [512, 512, 512]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/magenta/models/music_vae/lstm_utils.py:99: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/magenta/contrib/rnn.py:751: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/magenta/models/music_vae/base_model.py:189: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/magenta/contrib/rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n",
            "INFO:tensorflow:Restoring parameters from /content/model_chords_fb64.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n-f4i_Tby7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}